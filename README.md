# ğŸ¤– AI Interview Agent - HÆ°á»›ng dáº«n sá»­ dá»¥ng

## Tá»•ng quan
AI Interview Agent lÃ  má»™t cÃ´ng cá»¥ CLI chatbox tÆ°Æ¡ng tÃ¡c vá»›i **tÃ­ch há»£p AI Ollama llama3:8b** Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u tá»« cÃ¡c file .md vÃ  mÃ´ phá»ng phá»ng váº¥n kiáº¿n thá»©c vá» Hugging Face má»™t cÃ¡ch thÃ´ng minh vÃ  chÃ­nh xÃ¡c.

## âœ¨ TÃ­nh nÄƒng má»›i - Enhanced Workspace Loading

### ğŸ” Workspace Discovery & Smart Loading
- **Auto-discover**: Tá»± Ä‘á»™ng khÃ¡m phÃ¡ cáº¥u trÃºc workspace
- **Selective Loading**: Chá»n folders cá»¥ thá»ƒ Ä‘á»ƒ náº¡p
- **Multi-format Support**: Markdown, Python, JSON, YAML
- **Intelligent Parsing**: PhÃ¢n tÃ­ch code vÃ  trÃ­ch xuáº¥t thÃ´ng tin
- **Performance Optimization**: Cache vÃ  tá»‘i Æ°u memory

### ğŸ¤– AI Mode (Ollama llama3:8b) - Enhanced
- **Rich Context**: XÃ¢y dá»±ng context tá»« toÃ n bá»™ workspace
- **Smart Relevance**: TÃ­nh toÃ¡n Ä‘á»™ liÃªn quan thÃ´ng minh
- **Knowledge Fusion**: Káº¿t há»£p multiple sources
- **Confidence Scoring**: ÄÃ¡nh giÃ¡ Ä‘á»™ tin cáº­y nÃ¢ng cao
- **Enhanced Prompting**: System prompts Ä‘Æ°á»£c tá»‘i Æ°u

### ğŸ’¬ Interactive Commands - Expanded
- **Workspace Stats**: `stats` - Hiá»ƒn thá»‹ thá»‘ng kÃª workspace
- **Smart Search**: `search <keyword>` - TÃ¬m kiáº¿m trong knowledge base  
- **Folder Selection**: TÆ°Æ¡ng tÃ¡c chá»n folders khi loading
- **Real-time Metrics**: Theo dÃµi performance vÃ  usage

### ğŸ“š Rule-based Mode (Fallback)
- **Keyword Search**: TÃ¬m kiáº¿m dá»±a trÃªn tá»« khÃ³a
- **Smart Extraction**: TrÃ­ch xuáº¥t thÃ´ng tin cÆ¡ báº£n
- **Always Available**: Hoáº¡t Ä‘á»™ng khi AI khÃ´ng kháº£ dá»¥ng
- **Fast Response**: Pháº£n há»“i nhanh chÃ³ng

### ğŸ”„ Hybrid System
- **Auto-fallback**: Tá»± Ä‘á»™ng chuyá»ƒn sang rule-based náº¿u AI lá»—i
- **Toggle Mode**: Chuyá»ƒn Ä‘á»•i giá»¯a AI vÃ  rule-based báº±ng lá»‡nh `ai`
- **Smart Context**: XÃ¢y dá»±ng context thÃ´ng minh cho AI

## TÃ­nh nÄƒng chÃ­nh

### ğŸ¯ Cháº¿ Ä‘á»™ Interview (Phá»ng váº¥n)
- PhÃ¢n tÃ­ch cÃ¢u há»i tá»« file .md
- Táº¡o phiÃªn phá»ng váº¥n tÆ°Æ¡ng tÃ¡c
- Theo dÃµi Ä‘iá»ƒm sá»‘ vÃ  thá»‘ng kÃª
- ÄÆ°a ra lá»i khuyÃªn dá»±a trÃªn káº¿t quáº£

### ğŸ’¬ Cháº¿ Ä‘á»™ Chat (TrÃ² chuyá»‡n) - **Enhanced vá»›i AI**
- **AI-powered Chat**: TrÃ² chuyá»‡n thÃ´ng minh vá»›i Ollama LLM
- **Smart Q&A**: Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn kiáº¿n thá»©c Ä‘Ã£ táº£i
- **Context Building**: Tá»± Ä‘á»™ng xÃ¢y dá»±ng context tá»« knowledge base
- **Thinking Process**: Hiá»ƒn thá»‹ quÃ¡ trÃ¬nh suy luáº­n cá»§a AI
- **Confidence Scoring**: ÄÃ¡nh giÃ¡ Ä‘á»™ tin cáº­y cÃ¢u tráº£ lá»i

### ğŸ“Š PhÃ¢n tÃ­ch dá»¯ liá»‡u
- Tá»± Ä‘á»™ng phÃ¢n tÃ­ch file .md
- TrÃ­ch xuáº¥t cÃ¢u há»i vÃ  kiáº¿n thá»©c
- Táº¡o tá»« khÃ³a vÃ  liÃªn káº¿t ngá»¯ cáº£nh
- Hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t

## CÃ i Ä‘áº·t

### 1. YÃªu cáº§u há»‡ thá»‘ng
- Python 3.11+
- macOS/Linux/Windows
- Terminal/Command Prompt
- **Ollama (Optional - cho AI mode)**

### 2. CÃ i Ä‘áº·t thÆ° viá»‡n
```bash
# Táº¡o virtual environment
python3 -m venv venv

# KÃ­ch hoáº¡t virtual environment
source venv/bin/activate  # macOS/Linux
# hoáº·c
venv\Scripts\activate     # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### 3. CÃ i Ä‘áº·t Ollama (Optional - cho AI mode)
```bash
# macOS
brew install ollama

# Khá»Ÿi Ä‘á»™ng Ollama
ollama serve

# CÃ i Ä‘áº·t model llama3:8b
ollama pull llama3:8b
```

### 4. Cáº¥u trÃºc thÆ° viá»‡n
```
click>=8.0.0           # CLI framework
colorama>=0.4.6        # Terminal colors
rich>=13.0.0           # Rich text formatting
markdown>=3.4.0        # Markdown parsing
beautifulsoup4>=4.12.0 # HTML parsing
openai>=1.0.0          # OpenAI API (optional)
python-dotenv>=1.0.0   # Environment variables
```

## Sá»­ dá»¥ng

### CÃº phÃ¡p cÆ¡ báº£n
```bash
python main.py [FILES...] [OPTIONS]
```

### CÃ¡c tÃ¹y chá»n
- `-m, --mode [interview|chat|both]`: Chá»n cháº¿ Ä‘á»™ hoáº¡t Ä‘á»™ng
- `-s, --shuffle`: XÃ¡o trá»™n thá»© tá»± cÃ¢u há»i
- `-l, --limit INTEGER`: Giá»›i háº¡n sá»‘ lÆ°á»£ng cÃ¢u há»i
- `-v, --verbose`: Hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t
- `--help`: Hiá»ƒn thá»‹ trá»£ giÃºp

### VÃ­ dá»¥ sá»­ dá»¥ng nÃ¢ng cao

#### 1. Workspace Loading (Khuyáº¿n nghá»‹)
```bash
# Náº¡p toÃ n bá»™ workspace hiá»‡n táº¡i
python main.py --workspace . --mode chat

# Náº¡p workspace vá»›i Python analysis
python main.py --workspace . --include-python --mode both

# Chá»n folders cá»¥ thá»ƒ
python main.py --workspace . --folders "getting-started,pipelines,text-classification"

# Loáº¡i trá»« folders khÃ´ng cáº§n thiáº¿t
python main.py --workspace . --exclude-folders "__pycache__,node_modules" --include-python
```

#### 2. Advanced Configuration
```bash
# Giá»›i háº¡n kÃ­ch thÆ°á»›c file (2MB)
python main.py --workspace . --max-file-size 2097152

# Auto-discovery mode (khÃ´ng cáº§n chá»‰ Ä‘á»‹nh gÃ¬)
python main.py --mode chat

# Verbose mode Ä‘á»ƒ debug
python main.py --workspace . --verbose --include-python
```

#### 3. Traditional file loading (váº«n há»— trá»£)
```bash
# File riÃªng láº»
python main.py getting-started/questions.md getting-started/introduction.md

# Wildcard patterns
python main.py */questions.md --mode interview

# Vá»›i options
python main.py questions.md --shuffle --limit 10 --mode interview
```

## ğŸ¤– Sá»­ dá»¥ng AI Mode

### BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng Ollama
```bash
# Terminal 1: Khá»Ÿi Ä‘á»™ng Ollama server
ollama serve

# Terminal 2: CÃ i Ä‘áº·t model (chá»‰ cáº§n 1 láº§n)
ollama pull llama3:8b
```

### BÆ°á»›c 2: Cháº¡y Chat Mode
```bash
python main.py getting-started/introduction.md --mode chat
```

### BÆ°á»›c 3: Sá»­ dá»¥ng AI trong Chat
```
ğŸ’¬ Cháº¿ Ä‘á»™ Chat tÆ°Æ¡ng tÃ¡c (ğŸ¤– AI Ollama)
Báº¡n: Hugging Face lÃ  gÃ¬?

ğŸ¤– AI Assistant
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤– AI Ollama Response (Confidence: 85.0%)                                      â”‚
â”‚                                                                                 â”‚
â”‚ ğŸ’­ Thinking Process:                                                           â”‚
â”‚ Analyzing the question about Hugging Face, I need to extract key information   â”‚
â”‚ from the knowledge base about this platform...                                 â”‚
â”‚                                                                                 â”‚
â”‚ ğŸ“ Answer:                                                                     â”‚
â”‚ Hugging Face lÃ  má»™t ná»n táº£ng cá»™ng tÃ¡c cho cá»™ng Ä‘á»“ng AI/ML vá»›i cÃ¡c tÃ­nh nÄƒng:  â”‚
â”‚ â€¢ Model Repository: LÆ°u trá»¯ hÃ ng ngÃ n pre-trained models                       â”‚
â”‚ â€¢ Datasets: Bá»™ sÆ°u táº­p dá»¯ liá»‡u training                                       â”‚
â”‚ â€¢ Spaces: Demo á»©ng dá»¥ng AI tÆ°Æ¡ng tÃ¡c                                           â”‚
â”‚ â€¢ Transformers Library: ThÆ° viá»‡n Python dá»… sá»­ dá»¥ng                            â”‚
â”‚                                                                                 â”‚
â”‚ ğŸ” Source: AI Analysis + Knowledge Base                                        â”‚
â”‚ ğŸ“Š Knowledge Used: 1 documents                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### BÆ°á»›c 4: Chuyá»ƒn Ä‘á»•i cháº¿ Ä‘á»™
```
Báº¡n: ai
System: Chuyá»ƒn sang cháº¿ Ä‘á»™: ğŸ“š Rule-based

Báº¡n: ai  
System: Chuyá»ƒn sang cháº¿ Ä‘á»™: ğŸ¤– AI Ollama
```

### CÃ¡c lá»‡nh trong Chat Mode
- `ai` - Chuyá»ƒn Ä‘á»•i giá»¯a AI vÃ  Rule-based
- `interview` - Chuyá»ƒn sang cháº¿ Ä‘á»™ phá»ng váº¥n
- `quit` - ThoÃ¡t chÆ°Æ¡ng trÃ¬nh

## ğŸ”§ Demo vÃ  Test

### Demo Enhanced Features
```bash
# Cháº¡y demo Ä‘á»ƒ xem cÃ¡c tÃ­nh nÄƒng má»›i
python demo_enhanced_workspace.py

# Test workspace loading
python main.py --workspace . --folders "getting-started" --verbose

# Full workspace vá»›i AI (cáº§n Ollama)
ollama serve  # Terminal khÃ¡c
python main.py --workspace . --include-python --mode chat
```

### Test khÃ´ng cáº§n Ollama
```bash
# Cháº¡y rule-based mode
python main.py getting-started/introduction.md --mode chat
# Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng fallback sang rule-based
```

## Äá»‹nh dáº¡ng file input

### File cÃ¢u há»i (.md)
```markdown
## Question 1: exercise_1
**Title:** [TiÃªu Ä‘á» cÃ¢u há»i]

**Description:** [MÃ´ táº£ ngá»¯ cáº£nh]

**Question:** [CÃ¢u há»i chÃ­nh]

**Options:**
- [Lá»±a chá»n 1]
- [Lá»±a chá»n 2]
- [Lá»±a chá»n 3]
- [Lá»±a chá»n 4]

**Correct Answer:** [ÄÃ¡p Ã¡n Ä‘Ãºng]

**Explanation:** [Giáº£i thÃ­ch]

---
```

### File kiáº¿n thá»©c (.md)
```markdown
# TiÃªu Ä‘á» chÃ­nh

## Pháº§n 1
Ná»™i dung kiáº¿n thá»©c...

### Pháº§n con
Chi tiáº¿t kiáº¿n thá»©c...

## Pháº§n 2
Ná»™i dung khÃ¡c...
```

## TÆ°Æ¡ng tÃ¡c trong chÆ°Æ¡ng trÃ¬nh

### Cháº¿ Ä‘á»™ Interview
- Chá»n Ä‘Ã¡p Ã¡n: `1`, `2`, `3`, `4`
- Trá»£ giÃºp: `help` hoáº·c `h`
- ThoÃ¡t: `quit` hoáº·c `q`

### Cháº¿ Ä‘á»™ Chat
- Äáº·t cÃ¢u há»i: Nháº­p cÃ¢u há»i tá»± do
- Chuyá»ƒn sang phá»ng váº¥n: `interview`
- Trá»£ giÃºp: `help` hoáº·c `h`
- ThoÃ¡t: `quit` hoáº·c `q`

### Lá»‡nh chung
- `Ctrl+C`: ThoÃ¡t kháº©n cáº¥p
- `Enter`: XÃ¡c nháº­n lá»±a chá»n

## CÃ¡c tÃ­nh nÄƒng nÃ¢ng cao

### 1. PhÃ¢n tÃ­ch thÃ´ng minh
- Tá»± Ä‘á»™ng nháº­n diá»‡n file cÃ¢u há»i vÃ  kiáº¿n thá»©c
- TrÃ­ch xuáº¥t tá»« khÃ³a quan trá»ng
- LiÃªn káº¿t ngá»¯ cáº£nh giá»¯a cÃ¢u há»i vÃ  kiáº¿n thá»©c

### 2. Giao diá»‡n ngÆ°á»i dÃ¹ng
- Sá»­ dá»¥ng Rich library cho giao diá»‡n Ä‘áº¹p
- MÃ u sáº¯c phÃ¢n loáº¡i thÃ´ng tin
- Progress bar vÃ  spinner
- Báº£ng vÃ  panel thÃ´ng tin

### 3. Thá»‘ng kÃª vÃ  bÃ¡o cÃ¡o
- Theo dÃµi Ä‘iá»ƒm sá»‘ realtime
- Thá»‘ng kÃª thá»i gian lÃ m bÃ i
- ÄÃ¡nh giÃ¡ vÃ  lá»i khuyÃªn
- LÆ°u trá»¯ lá»‹ch sá»­ (tÃ¹y chá»n)

### 4. Xá»­ lÃ½ lá»—i
- Xá»­ lÃ½ file khÃ´ng tá»“n táº¡i
- Validation input ngÆ°á»i dÃ¹ng
- Graceful error handling
- Logging chi tiáº¿t (verbose mode)

## Kháº¯c phá»¥c sá»± cá»‘

### Lá»—i thÆ°á»ng gáº·p

#### 1. ModuleNotFoundError
```
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    import click
ModuleNotFoundError: No module named 'click'
```

**Giáº£i phÃ¡p:**
```bash
pip install -r requirements.txt
```

#### 2. File not found
```
âŒ Cáº§n chá»‰ Ä‘á»‹nh Ã­t nháº¥t má»™t file .md!
```

**Giáº£i phÃ¡p:**
```bash
python main.py getting-started/questions.md getting-started/introduction.md
```

#### 3. Externally managed environment
```
error: externally-managed-environment
```

**Giáº£i phÃ¡p:**
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Debug mode
```bash
python main.py *.md --verbose
```

### Kiá»ƒm tra cÃ i Ä‘áº·t
```bash
python main.py --help
```

## Má»Ÿ rá»™ng

### ThÃªm cÃ¢u há»i má»›i
1. Má»Ÿ file questions.md
2. Copy template tá»« cuá»‘i file
3. Thay tháº¿ cÃ¡c placeholder
4. Äáº£m báº£o exercise_id duy nháº¥t
5. Test vá»›i CLI

### ThÃªm kiáº¿n thá»©c má»›i
1. Táº¡o file .md má»›i
2. Sá»­ dá»¥ng cáº¥u trÃºc heading markdown
3. ThÃªm tá»« khÃ³a quan trá»ng
4. Load vá»›i CLI

### TÃ¹y chá»‰nh giao diá»‡n
- Chá»‰nh sá»­a colors trong code
- Thay Ä‘á»•i Panel styles
- Cáº­p nháº­t Table formats

## LiÃªn há»‡ vÃ  Ä‘Ã³ng gÃ³p

### BÃ¡o lá»—i
- Táº¡o issue trÃªn GitHub
- MÃ´ táº£ chi tiáº¿t lá»—i
- Cung cáº¥p log file

### ÄÃ³ng gÃ³p
- Fork repository
- Táº¡o branch má»›i
- Submit pull request

### PhÃ¡t triá»ƒn
- ThÃªm tÃ­nh nÄƒng má»›i
- Cáº£i thiá»‡n hiá»‡u suáº¥t
- Viáº¿t test cases

---

**PhiÃªn báº£n:** 1.0.0  
**NgÃ y cáº­p nháº­t:** 3 thÃ¡ng 7, 2025  
**TÃ¡c giáº£:** AI Interview TuTran Studio
