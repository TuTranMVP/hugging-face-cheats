#!/usr/bin/env python3
"""
AI Interview Agent - Hugging Face Knowledge Assessment
CLI Chatbox ƒë·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu t·ª´ file .md v√† m√¥ ph·ªèng ph·ªèng v·∫•n v·ªõi Gemini AI
"""

from dataclasses import dataclass
from datetime import datetime
import os
from pathlib import Path
import random
import re
import sys
from typing import Any, Dict, List, Optional

from bs4 import BeautifulSoup
import click
import colorama
from dotenv import load_dotenv
import google.generativeai as genai
import markdown
from rich.console import Console
from rich.panel import Panel
from rich.progress import BarColumn, Progress, SpinnerColumn, TextColumn
from rich.prompt import Confirm, Prompt
from rich.table import Table

# Load environment variables
load_dotenv()

# Kh·ªüi t·∫°o colorama cho Windows
colorama.init(autoreset=True)

# Kh·ªüi t·∫°o Rich console
console = Console()


@dataclass
class Question:
    """C·∫•u tr√∫c d·ªØ li·ªáu cho c√¢u h·ªèi"""

    id: str
    title: str
    description: str
    question: str
    options: List[str]
    correct_answer: str
    explanation: str
    difficulty: str = 'medium'
    topic: str = 'general'


@dataclass
class Knowledge:
    """C·∫•u tr√∫c d·ªØ li·ªáu cho ki·∫øn th·ª©c"""

    title: str
    content: str
    source_file: str
    sections: List[str]
    keywords: List[str]
    folder: str = ''
    file_type: str = 'markdown'
    importance_score: float = 1.0


@dataclass
class WorkspaceConfig:
    """C·∫•u h√¨nh workspace loading"""

    include_folders: Optional[List[str]] = None  # Folders to include
    exclude_folders: Optional[List[str]] = None  # Folders to exclude
    file_patterns: Optional[List[str]] = None  # File patterns to match
    max_file_size: int = 1024 * 1024  # Max file size in bytes
    enable_code_analysis: bool = True  # Analyze .py files
    enable_auto_summary: bool = True  # Auto generate summaries


class WorkspaceLoader:
    """N√¢ng c·∫•p ƒë·ªÉ n·∫°p to√†n b·ªô workspace th√¥ng minh"""

    def __init__(self, config: Optional[WorkspaceConfig] = None):
        self.config = config or WorkspaceConfig()
        self.md_parser = markdown.Markdown(extensions=['extra', 'toc'])
        self.supported_extensions = {'.md', '.txt', '.py', '.json', '.yml', '.yaml'}

    def discover_workspace(self, root_path: str) -> Dict[str, List[str]]:
        """Kh√°m ph√° c·∫•u tr√∫c workspace"""
        workspace_structure = {
            'folders': [],
            'markdown_files': [],
            'python_files': [],
            'config_files': [],
            'question_files': [],
            'knowledge_files': [],
        }

        root = Path(root_path)

        for path in root.rglob('*'):
            if path.is_dir():
                if self._should_include_folder(str(path.relative_to(root))):
                    workspace_structure['folders'].append(str(path))
            elif path.is_file():
                rel_path = str(path.relative_to(root))
                if self._should_include_file(rel_path):
                    if path.suffix == '.md':
                        if 'question' in path.name.lower():
                            workspace_structure['question_files'].append(str(path))
                        else:
                            workspace_structure['knowledge_files'].append(str(path))
                        workspace_structure['markdown_files'].append(str(path))
                    elif path.suffix == '.py':
                        workspace_structure['python_files'].append(str(path))
                    elif path.suffix in {'.json', '.yml', '.yaml'}:
                        workspace_structure['config_files'].append(str(path))

        return workspace_structure

    def load_workspace_content(
        self, root_path: str, selected_folders: Optional[List[str]] = None
    ) -> List[Knowledge]:
        """N·∫°p n·ªôi dung workspace v·ªõi t√πy ch·ªçn folder"""
        knowledge_base = []

        if selected_folders:
            # Load specific folders
            for folder in selected_folders:
                folder_path = Path(root_path) / folder
                if folder_path.exists():
                    knowledge_base.extend(
                        self._load_folder_content(folder_path, folder)
                    )
        else:
            # Load all workspace
            workspace_structure = self.discover_workspace(root_path)

            # Load markdown files
            for md_file in workspace_structure['knowledge_files']:
                knowledge = self._load_markdown_file(md_file)
                if knowledge:
                    knowledge_base.append(knowledge)

            # Load Python files if enabled
            if self.config.enable_code_analysis:
                for py_file in workspace_structure['python_files']:
                    knowledge = self._load_python_file(py_file)
                    if knowledge:
                        knowledge_base.append(knowledge)

        return knowledge_base

    def _load_folder_content(
        self, folder_path: Path, folder_name: str
    ) -> List[Knowledge]:
        """N·∫°p n·ªôi dung t·ª´ m·ªôt folder c·ª• th·ªÉ"""
        knowledge_list = []

        for file_path in folder_path.rglob('*'):
            if file_path.is_file() and file_path.suffix in self.supported_extensions:
                if file_path.suffix == '.md':
                    knowledge = self._load_markdown_file(str(file_path))
                elif file_path.suffix == '.py':
                    knowledge = self._load_python_file(str(file_path))
                else:
                    knowledge = self._load_text_file(str(file_path))

                if knowledge:
                    knowledge.folder = folder_name
                    knowledge_list.append(knowledge)

        return knowledge_list

    def _load_markdown_file(self, file_path: str) -> Optional[Knowledge]:
        """N√¢ng c·∫•p load markdown v·ªõi ph√¢n t√≠ch s√¢u h∆°n"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()

            # Convert markdown to HTML for better parsing
            html_content = self.md_parser.convert(content)
            _soup = BeautifulSoup(html_content, 'html.parser')

            # Extract title
            title = self._extract_title(content, file_path)

            # Extract sections
            sections = self._extract_sections(content)

            # Extract keywords
            keywords = self._extract_keywords(content)

            # Calculate importance score
            importance_score = self._calculate_importance_score(content, file_path)

            return Knowledge(
                title=title,
                content=content,
                source_file=file_path,
                sections=sections,
                keywords=keywords,
                folder=str(Path(file_path).parent.name),
                file_type='markdown',
                importance_score=importance_score,
            )

        except Exception as e:
            console.print(f'[red]L·ªói khi ƒë·ªçc file {file_path}: {e}[/red]')
            return None

    def _load_python_file(self, file_path: str) -> Optional[Knowledge]:
        """N·∫°p v√† ph√¢n t√≠ch file Python"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()

            # Extract docstrings and comments
            title = f'Python Code: {Path(file_path).name}'

            # Extract function and class definitions
            sections = self._extract_python_elements(content)

            # Extract technical keywords
            keywords = self._extract_python_keywords(content)

            # Create summarized content
            summary_content = self._create_python_summary(content)

            return Knowledge(
                title=title,
                content=summary_content,
                source_file=file_path,
                sections=sections,
                keywords=keywords,
                folder=str(Path(file_path).parent.name),
                file_type='python',
                importance_score=0.8,  # Slightly lower than markdown
            )

        except Exception as e:
            console.print(f'[red]L·ªói khi ƒë·ªçc file Python {file_path}: {e}[/red]')
            return None

    def _load_text_file(self, file_path: str) -> Optional[Knowledge]:
        """N·∫°p file text th√¥ng th∆∞·ªùng"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()

            if len(content) > self.config.max_file_size:
                content = (
                    content[: self.config.max_file_size] + '...\n[Content truncated]'
                )

            title = f'Text File: {Path(file_path).name}'
            keywords = self._extract_keywords(content)

            return Knowledge(
                title=title,
                content=content,
                source_file=file_path,
                sections=[],
                keywords=keywords,
                folder=str(Path(file_path).parent.name),
                file_type='text',
                importance_score=0.5,
            )

        except Exception as e:
            console.print(f'[red]L·ªói khi ƒë·ªçc file text {file_path}: {e}[/red]')
            return None

    def _should_include_folder(self, folder_path: str) -> bool:
        """Ki·ªÉm tra c√≥ n√™n include folder kh√¥ng"""
        # Exclude common unnecessary folders
        exclude_defaults = {
            '.git',
            '__pycache__',
            '.vscode',
            'node_modules',
            '.pytest_cache',
        }

        folder_name = Path(folder_path).name
        if folder_name in exclude_defaults:
            return False

        if self.config.exclude_folders:
            if any(excluded in folder_path for excluded in self.config.exclude_folders):
                return False

        if self.config.include_folders:
            return any(
                included in folder_path for included in self.config.include_folders
            )

        return True

    def _should_include_file(self, file_path: str) -> bool:
        """Ki·ªÉm tra c√≥ n√™n include file kh√¥ng"""
        path = Path(file_path)

        # Check file size
        try:
            if path.stat().st_size > self.config.max_file_size:
                return False
        except:  # noqa: E722
            return False

        # Check extension
        if path.suffix not in self.supported_extensions:
            return False

        # Check patterns
        if self.config.file_patterns:
            return any(pattern in file_path for pattern in self.config.file_patterns)

        return True

    def _extract_title(self, content: str, file_path: str) -> str:
        """Tr√≠ch xu·∫•t title th√¥ng minh"""
        # Try to find first H1 heading
        h1_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
        if h1_match:
            return h1_match.group(1).strip()

        # Try to find title in front matter
        frontmatter_match = re.search(r'^---\s*\ntitle:\s*(.+)$', content, re.MULTILINE)
        if frontmatter_match:
            return frontmatter_match.group(1).strip()

        # Use filename as fallback
        return Path(file_path).stem.replace('_', ' ').replace('-', ' ').title()

    def _extract_sections(self, content: str) -> List[str]:
        """Tr√≠ch xu·∫•t c√°c sections t·ª´ markdown"""
        sections = []

        # Find all headings
        heading_pattern = r'^(#{1,6})\s+(.+)$'
        for match in re.finditer(heading_pattern, content, re.MULTILINE):
            level = len(match.group(1))
            title = match.group(2).strip()
            sections.append(f'{"  " * (level - 1)}{title}')

        return sections

    def _extract_keywords(self, content: str) -> List[str]:
        """Tr√≠ch xu·∫•t keywords th√¥ng minh"""
        keywords = set()

        # Technical terms (capitalize words)
        tech_terms = re.findall(r'\b[A-Z][a-z]+(?:[A-Z][a-z]*)*\b', content)
        keywords.update(tech_terms[:20])

        # Common ML/AI terms
        ml_terms = [
            'hugging face',
            'transformers',
            'model',
            'pipeline',
            'tokenizer',
            'dataset',
            'training',
            'inference',
            'api',
            'nlp',
            'llm',
            'bert',
            'gpt',
            'embedding',
            'fine-tuning',
            'classification',
            'summarization',
        ]

        content_lower = content.lower()
        for term in ml_terms:
            if term in content_lower:
                keywords.add(term)

        # Extract quoted terms
        quoted_terms = re.findall(r'["\']([^"\']+)["\']', content)
        keywords.update(
            [term for term in quoted_terms if len(term) > 2 and len(term) < 30]
        )

        return list(keywords)[:30]  # Limit to 30 keywords

    def _calculate_importance_score(self, content: str, file_path: str) -> float:
        """T√≠nh ƒëi·ªÉm quan tr·ªçng c·ªßa file"""
        score = 1.0

        # File name indicators
        filename = Path(file_path).name.lower()
        if 'readme' in filename:
            score += 0.5
        if 'introduction' in filename:
            score += 0.3
        if 'question' in filename:
            score += 0.4

        # Content quality indicators
        if len(content) > 1000:
            score += 0.2
        if '```' in content:  # Has code blocks
            score += 0.1
        if content.count('#') > 3:  # Well structured
            score += 0.1

        return min(score, 2.0)  # Cap at 2.0

    def _extract_python_elements(self, content: str) -> List[str]:
        """Tr√≠ch xu·∫•t c√°c elements t·ª´ Python code"""
        elements = []

        # Find functions
        func_pattern = r'def\s+(\w+)\s*\([^)]*\):'
        for match in re.finditer(func_pattern, content):
            elements.append(f'Function: {match.group(1)}')

        # Find classes
        class_pattern = r'class\s+(\w+)(?:\([^)]*\))?:'
        for match in re.finditer(class_pattern, content):
            elements.append(f'Class: {match.group(1)}')

        return elements

    def _extract_python_keywords(self, content: str) -> List[str]:
        """Tr√≠ch xu·∫•t keywords t·ª´ Python code"""
        keywords = set()

        # Import statements
        import_pattern = r'(?:from\s+(\S+)\s+)?import\s+([^#\n]+)'
        for match in re.finditer(import_pattern, content):
            if match.group(1):
                keywords.add(match.group(1))
            imports = match.group(2).split(',')
            keywords.update([imp.strip() for imp in imports])

        # Function and class names
        func_class_pattern = r'(?:def|class)\s+(\w+)'
        for match in re.finditer(func_class_pattern, content):
            keywords.add(match.group(1))

        return list(keywords)[:20]

    def _create_python_summary(self, content: str) -> str:
        """T·∫°o summary cho Python file"""
        lines = content.split('\n')
        summary_lines = []

        # Add docstring if exists
        if '"""' in content:
            in_docstring = False
            for line in lines:
                if '"""' in line and not in_docstring:
                    in_docstring = True
                    summary_lines.append(line)
                elif '"""' in line and in_docstring:
                    summary_lines.append(line)
                    break
                elif in_docstring:
                    summary_lines.append(line)

        # Add function/class definitions
        for line in lines:
            if line.strip().startswith(('def ', 'class ', 'import ', 'from ')):
                summary_lines.append(line)

        return '\n'.join(summary_lines[:50])  # Limit to 50 lines


class MarkdownParser:
    """Parser ƒë·ªÉ ph√¢n t√≠ch file markdown"""

    def __init__(self):
        self.md = markdown.Markdown(extensions=['extra', 'toc'])

    def parse_questions(self, file_path: str) -> List[Question]:
        """Ph√¢n t√≠ch file markdown ch·ª©a c√¢u h·ªèi"""
        questions = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # T√°ch c√°c c√¢u h·ªèi b·∫±ng d·∫•u ---
            question_blocks = content.split('---')

            for block in question_blocks:
                if 'exercise_' in block and (
                    '**Question:**' in block or '**C√¢u h·ªèi:**' in block
                ):
                    question = self._parse_question_block(block)
                    if question:
                        questions.append(question)

        except Exception as e:
            console.print(f'[red]L·ªói khi ƒë·ªçc file {file_path}: {e}[/red]')

        return questions

    def _parse_question_block(self, block: str) -> Optional[Question]:
        """Ph√¢n t√≠ch m·ªôt block c√¢u h·ªèi"""
        try:
            # T√¨m exercise ID
            exercise_match = re.search(r'exercise_(\w+)', block)
            if not exercise_match:
                return None

            exercise_id = exercise_match.group(1)

            # T√¨m title (h·ªó tr·ª£ c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát)
            title_match = re.search(r'\*\*(?:Title|Ti√™u ƒë·ªÅ):\*\*\s*(.+)', block)
            title = (
                title_match.group(1).strip()
                if title_match
                else f'Question {exercise_id}'
            )

            # T√¨m description (h·ªó tr·ª£ c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát)
            desc_match = re.search(r'\*\*(?:Description|M√¥ t·∫£):\*\*\s*(.+)', block)
            description = desc_match.group(1).strip() if desc_match else ''

            # T√¨m question (h·ªó tr·ª£ c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát)
            question_match = re.search(r'\*\*(?:Question|C√¢u h·ªèi):\*\*\s*(.+)', block)
            question = question_match.group(1).strip() if question_match else ''

            # T√¨m options (h·ªó tr·ª£ c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát)
            options_section = re.search(
                r'\*\*(?:Options|C√°c l·ª±a ch·ªçn):\*\*\s*\n((?:- .+\n?)+)', block
            )
            options = []
            if options_section:
                option_lines = options_section.group(1).strip().split('\n')
                options = [
                    line.strip('- ').strip()
                    for line in option_lines
                    if line.strip().startswith('- ')
                ]

            # T√¨m correct answer (h·ªó tr·ª£ c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát)
            answer_match = re.search(
                r'\*\*(?:Correct Answer|ƒê√°p √°n ƒë√∫ng):\*\*\s*(.+)', block
            )
            correct_answer = answer_match.group(1).strip() if answer_match else ''

            # T√¨m explanation (h·ªó tr·ª£ c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát)
            explanation_match = re.search(
                r'\*\*(?:Explanation|Gi·∫£i th√≠ch):\*\*\s*(.+)', block
            )
            explanation = (
                explanation_match.group(1).strip() if explanation_match else ''
            )

            return Question(
                id=exercise_id,
                title=title,
                description=description,
                question=question,
                options=options,
                correct_answer=correct_answer,
                explanation=explanation,
            )

        except Exception as e:
            console.print(f'[red]L·ªói khi ph√¢n t√≠ch c√¢u h·ªèi: {e}[/red]')
            return None

    def parse_knowledge(self, file_path: str) -> Knowledge:
        """Ph√¢n t√≠ch file markdown ch·ª©a ki·∫øn th·ª©c"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # Parse markdown
            html = self.md.convert(content)
            soup = BeautifulSoup(html, 'html.parser')

            # L·∫•y title (h1 ƒë·∫ßu ti√™n)
            title_tag = soup.find('h1')
            title = title_tag.get_text().strip() if title_tag else Path(file_path).stem

            # L·∫•y c√°c section (h2, h3)
            sections = []
            for heading in soup.find_all(['h2', 'h3']):
                sections.append(heading.get_text().strip())

            # T·∫°o keywords t·ª´ headings v√† content
            keywords = []
            text_content = soup.get_text()

            # Th√™m t·ª´ kh√≥a t·ª´ headings
            keywords.extend([s.lower() for s in sections])

            # T√¨m t·ª´ kh√≥a quan tr·ªçng (c√≥ th·ªÉ c·∫£i thi·ªán b·∫±ng NLP)
            important_words = re.findall(
                r'\b(?:Hugging Face|LLM|Model|API|Hub|Dataset|Fine-tuning|Transformer|GPT|BERT|Llama)\b',
                text_content,
                re.IGNORECASE,
            )
            keywords.extend([w.lower() for w in important_words])

            return Knowledge(
                title=title,
                content=content,
                source_file=file_path,
                sections=sections,
                keywords=list(set(keywords)),  # Remove duplicates
            )

        except Exception as e:
            console.print(f'[red]L·ªói khi ƒë·ªçc file {file_path}: {e}[/red]')
            return None  # type: ignore


@dataclass
class AIResponse:
    """C·∫•u tr√∫c ph·∫£n h·ªìi t·ª´ AI"""

    content: str
    source: str = 'ai'
    confidence: float = 0.0
    thinking_process: str = ''
    knowledge_used: Optional[List[str]] = None

    def __post_init__(self):
        if self.knowledge_used is None:
            self.knowledge_used = []


class GeminiAI:
    """T√≠ch h·ª£p AI Gemini 2.0 Flash - Thay th·∫ø ho√†n to√†n rule-based"""

    def __init__(
        self,
        model_name: Optional[str] = None,
        api_key: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 2048,
    ):
        self.model_name = model_name or os.getenv('GEMINI_MODEL', 'gemini-2.0-flash')
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.is_available = False
        self.model = None
        self._initialize()

    def _initialize(self):
        """Kh·ªüi t·∫°o Gemini AI"""
        if not self.api_key:
            console.print('[red]‚ùå GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh trong .env[/red]')
            console.print(
                '[dim]H√£y th√™m GEMINI_API_KEY=your_key_here v√†o file .env[/dim]'
            )
            return

        try:
            genai.configure(api_key=self.api_key)  # type: ignore

            # Test API connection
            self.model = genai.GenerativeModel(self.model_name)  # type: ignore

            # Test with a simple query
            test_response = self.model.generate_content(
                'Test connection',
                generation_config=genai.types.GenerationConfig(  # type: ignore
                    temperature=0.1, max_output_tokens=10
                ),
            )

            if test_response and test_response.text:
                self.is_available = True
                console.print(f'[green]‚úì Gemini {self.model_name} ƒë√£ s·∫µn s√†ng![/green]')
            else:
                console.print('[yellow]‚ö† Gemini API response kh√¥ng h·ª£p l·ªá[/yellow]')

        except Exception as e:
            console.print(f'[red]‚ùå L·ªói k·∫øt n·ªëi Gemini API: {e}[/red]')
            console.print('[dim]Ki·ªÉm tra API key v√† k·∫øt n·ªëi internet[/dim]')

    def generate_response(
        self,
        prompt: str,
        context: str = '',
        max_tokens: int = None,  # type: ignore
    ) -> AIResponse:
        """T·∫°o ph·∫£n h·ªìi t·ª´ Gemini AI v·ªõi advanced knowledge fusion"""
        if not self.is_available:
            return AIResponse(
                content='‚ùå Gemini AI kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra API key.',
                source='error',
                confidence=0.0,
            )

        try:
            # Build enhanced system prompt with workspace knowledge
            system_prompt = self._create_advanced_system_prompt(context, prompt)

            # Configure generation parameters
            generation_config = genai.types.GenerationConfig(  # type: ignore
                temperature=self.temperature,
                max_output_tokens=max_tokens or self.max_tokens,
                top_p=0.9,
                top_k=40,
            )

            # Generate response with safety settings
            safety_settings = [
                {
                    'category': 'HARM_CATEGORY_HARASSMENT',
                    'threshold': 'BLOCK_MEDIUM_AND_ABOVE',
                },
                {
                    'category': 'HARM_CATEGORY_HATE_SPEECH',
                    'threshold': 'BLOCK_MEDIUM_AND_ABOVE',
                },
                {
                    'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',
                    'threshold': 'BLOCK_MEDIUM_AND_ABOVE',
                },
                {
                    'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',
                    'threshold': 'BLOCK_MEDIUM_AND_ABOVE',
                },
            ]

            response = self.model.generate_content(  # type: ignore
                system_prompt,
                generation_config=generation_config,
                safety_settings=safety_settings,
            )

            if response and response.text:
                ai_response = response.text.strip()

                # Extract thinking process if present
                thinking_process = ''
                knowledge_used = []

                if '<thinking>' in ai_response:
                    thinking_match = re.search(
                        r'<thinking>(.*?)</thinking>', ai_response, re.DOTALL
                    )
                    if thinking_match:
                        thinking_process = thinking_match.group(1).strip()
                        ai_response = re.sub(
                            r'<thinking>.*?</thinking>',
                            '',
                            ai_response,
                            flags=re.DOTALL,
                        ).strip()

                # Extract knowledge sources used
                if '<sources>' in ai_response:
                    sources_match = re.search(
                        r'<sources>(.*?)</sources>', ai_response, re.DOTALL
                    )
                    if sources_match:
                        sources_text = sources_match.group(1).strip()
                        knowledge_used = [s.strip() for s in sources_text.split(',')]
                        ai_response = re.sub(
                            r'<sources>.*?</sources>',
                            '',
                            ai_response,
                            flags=re.DOTALL,
                        ).strip()

                # Calculate confidence based on response quality and context relevance
                confidence = self._calculate_confidence(ai_response, context, prompt)

                return AIResponse(
                    content=ai_response,
                    source='gemini',
                    confidence=confidence,
                    thinking_process=thinking_process,
                    knowledge_used=knowledge_used,
                )
            else:
                console.print('[yellow]‚ö† Gemini tr·∫£ v·ªÅ response tr·ªëng[/yellow]')
                return AIResponse(
                    content='‚ùå Gemini kh√¥ng th·ªÉ t·∫°o response ph√π h·ª£p',
                    source='error',
                    confidence=0.0,
                )

        except Exception as e:
            console.print(f'[red]L·ªói Gemini API: {e}[/red]')
            return AIResponse(
                content=f'‚ùå L·ªói khi g·ªçi Gemini API: {str(e)}',
                source='error',
                confidence=0.0,
            )

    def _create_advanced_system_prompt(self, context: str, user_question: str) -> str:
        """T·∫°o advanced system prompt v·ªõi knowledge fusion"""

        # Analyze context to extract key information
        context_analysis = self._analyze_context(context)
        question_intent = self._analyze_question_intent(user_question)

        return f"""B·∫°n l√† AI Interview Expert chuy√™n s√¢u v·ªÅ Hugging Face v√† Machine Learning, ƒë∆∞·ª£c t√≠ch h·ª£p v·ªõi knowledge base workspace th·ª±c t·∫ø.

üìä WORKSPACE KNOWLEDGE ANALYSIS:
{context_analysis}

üéØ QUESTION INTENT: {question_intent}

üß† KNOWLEDGE CONTEXT:
{context[:3000]}...

üìã NHI·ªÜM V·ª§ CH√çNH:
1. Ph√¢n t√≠ch c√¢u h·ªèi m·ªôt c√°ch s√¢u s·∫Øc v√† ch√≠nh x√°c
2. K·∫øt h·ª£p ki·∫øn th·ª©c t·ª´ workspace v·ªõi ki·∫øn th·ª©c c·∫≠p nh·∫≠t c·ªßa Gemini
3. ƒê∆∞a ra c√¢u tr·∫£ l·ªùi chuy√™n m√¥n, th·ª±c t·∫ø v√† h·ªØu √≠ch
4. T·ªëi ∆∞u h√≥a cho m·ª•c ƒë√≠ch ph·ªèng v·∫•n v√† ƒë√°nh gi√° nƒÉng l·ª±c

üîß QUY T·∫ÆC TR·∫¢I NGHI·ªÜM:
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n, chuy√™n nghi·ªáp
- S·ª≠ d·ª•ng emoji ph√π h·ª£p (ü§ñüöÄüìöüí°üéØ‚ö°Ô∏èüîç‚úÖ)
- KH√îNG d√πng markdown formatting (**,*,`,#)
- ∆Øu ti√™n th√¥ng tin t·ª´ workspace khi c√≥ li√™n quan
- B·ªï sung ki·∫øn th·ª©c m·ªõi nh·∫•t t·ª´ Gemini khi c·∫ßn thi·∫øt
- Cung c·∫•p examples c·ª• th·ªÉ v√† practical

üéì CHUY√äN M√îN FOCUS:
- Hugging Face ecosystem (Hub, Transformers, Datasets, Spaces)
- Machine Learning workflows v√† best practices
- Python programming trong ML context
- Real-world applications v√† troubleshooting

üí≠ THINKING PROCESS:
N·∫øu c·∫ßn ph√¢n t√≠ch ph·ª©c t·∫°p, wrap trong <thinking></thinking>
N·∫øu s·ª≠ d·ª•ng sources, list trong <sources>file1.md, file2.py</sources>

H√£y ph√¢n t√≠ch c√¢u h·ªèi "{user_question}" v√† ƒë∆∞a ra c√¢u tr·∫£ l·ªùi chuy√™n m√¥n t·ªët nh·∫•t!"""

    def _analyze_context(self, context: str) -> str:
        """Ph√¢n t√≠ch context ƒë·ªÉ t·∫°o summary th√¥ng minh"""
        if not context or len(context) < 100:
            return 'üìã Limited context available'

        # Count different types of content
        sections = len(re.findall(r'##\s+', context))
        code_blocks = len(re.findall(r'```', context))
        questions = len(re.findall(r'[Qq]uestion|[Cc]√¢u h·ªèi', context))

        # Extract key topics
        ml_terms = []
        key_terms = [
            'hugging face',
            'transformer',
            'model',
            'dataset',
            'pipeline',
            'tokenizer',
            'api',
            'hub',
            'training',
            'inference',
        ]

        for term in key_terms:
            if term in context.lower():
                ml_terms.append(term)

        analysis = f"""
üìä Content: {len(context)} chars, {sections} sections, {code_blocks} code blocks
‚ùì Questions found: {questions}
üéØ Key topics: {', '.join(ml_terms[:5]) if ml_terms else 'General ML'}
üìà Relevance: High workspace integration available"""

        return analysis.strip()

    def _analyze_question_intent(self, question: str) -> str:
        """Ph√¢n t√≠ch intent c·ªßa c√¢u h·ªèi"""
        question_lower = question.lower()

        if any(
            word in question_lower
            for word in ['l√† g√¨', 'what is', 'define', 'ƒë·ªãnh nghƒ©a']
        ):
            return 'Definition/Explanation Request'
        elif any(
            word in question_lower
            for word in ['how to', 'l√†m th·∫ø n√†o', 'c√°ch', 'steps']
        ):
            return 'How-to/Tutorial Request'
        elif any(
            word in question_lower for word in ['why', 't·∫°i sao', 'l√Ω do', 'benefit']
        ):
            return 'Reasoning/Benefits Inquiry'
        elif any(
            word in question_lower
            for word in ['compare', 'so s√°nh', 'difference', 'kh√°c nhau']
        ):
            return 'Comparison Analysis'
        elif any(
            word in question_lower for word in ['example', 'v√≠ d·ª•', 'demo', 'sample']
        ):
            return 'Example/Demo Request'
        elif any(
            word in question_lower
            for word in ['error', 'l·ªói', 'problem', 'issue', 'fix']
        ):
            return 'Troubleshooting Help'
        else:
            return 'General Knowledge Query'

    def _calculate_confidence(
        self, response: str, context: str, question: str
    ) -> float:
        """T√≠nh to√°n confidence score based on multiple factors"""
        base_confidence = 0.7

        # Response quality factors
        if len(response) > 100:
            base_confidence += 0.1
        if len(response) > 300:
            base_confidence += 0.1

        # Context relevance
        question_keywords = set(re.findall(r'\b\w{4,}\b', question.lower()))
        context_keywords = set(re.findall(r'\b\w{4,}\b', context.lower()[:1000]))
        response_keywords = set(re.findall(r'\b\w{4,}\b', response.lower()))

        # Keyword overlap scoring
        if question_keywords:
            context_overlap = len(question_keywords & context_keywords) / len(
                question_keywords
            )
            response_relevance = len(question_keywords & response_keywords) / len(
                question_keywords
            )

            base_confidence += context_overlap * 0.15
            base_confidence += response_relevance * 0.1

        # Technical content indicators
        if any(
            term in response.lower()
            for term in ['hugging face', 'model', 'api', 'code', 'python']
        ):
            base_confidence += 0.05

        # Structure and formatting quality
        if '‚Ä¢' in response or 'v√≠ d·ª•' in response.lower():
            base_confidence += 0.05

        return min(0.95, base_confidence)  # Cap at 95%


class InterviewAgent:
    """AI Agent ƒë·ªÉ m√¥ ph·ªèng ph·ªèng v·∫•n - Enhanced v·ªõi workspace loading"""

    def __init__(self):
        self.questions = []
        self.knowledge_base = []
        self.current_question = None
        self.score = 0
        self.answered_questions = []
        self.session_stats = {
            'total_questions': 0,
            'correct_answers': 0,
            'start_time': None,
            'end_time': None,
        }
        self.workspace_loader = WorkspaceLoader()
        self.workspace_structure = {}

    def load_workspace(
        self, root_path: str, config: Optional[WorkspaceConfig] = None
    ) -> Dict[str, Any]:
        """N·∫°p to√†n b·ªô workspace v·ªõi configuration"""
        if config:
            self.workspace_loader.config = config

        console.print(f'\n[bold blue]üîç Kh√°m ph√° workspace: {root_path}[/bold blue]')

        # Discover workspace structure
        self.workspace_structure = self.workspace_loader.discover_workspace(root_path)

        # Display workspace structure
        self._display_workspace_structure()

        # Ask user which folders to load
        selected_folders = self._select_folders_to_load()

        # Load content
        with Progress(
            SpinnerColumn(),
            TextColumn('[progress.description]{task.description}'),
            BarColumn(),
            console=console,
        ) as progress:
            task = progress.add_task('ƒêang n·∫°p workspace...', total=100)

            # Load knowledge base
            progress.update(task, description='N·∫°p knowledge base...', completed=20)
            self.knowledge_base = self.workspace_loader.load_workspace_content(
                root_path, selected_folders
            )

            # Load questions from discovered question files
            progress.update(task, description='N·∫°p c√¢u h·ªèi...', completed=60)
            parser = MarkdownParser()
            for question_file in self.workspace_structure['question_files']:
                questions = parser.parse_questions(question_file)
                self.questions.extend(questions)

            progress.update(task, description='Ho√†n th√†nh!', completed=100)

        # Display loading results
        self._display_loading_results()

        return {
            'knowledge_count': len(self.knowledge_base),
            'question_count': len(self.questions),
            'folders_loaded': selected_folders or 'all',
            'workspace_structure': self.workspace_structure,
        }

    def _display_workspace_structure(self):
        """Hi·ªÉn th·ªã c·∫•u tr√∫c workspace"""
        table = Table(title='üìÅ C·∫•u tr√∫c Workspace', title_style='bold blue')
        table.add_column('Lo·∫°i', style='cyan', width=20)
        table.add_column('S·ªë l∆∞·ª£ng', justify='right', style='magenta')
        table.add_column('Chi ti·∫øt', style='white')

        table.add_row(
            'üìÇ Folders',
            str(len(self.workspace_structure['folders'])),
            f'C√≥ th·ªÉ ch·ªçn: {len(self.workspace_structure["folders"])}',
        )
        table.add_row(
            'üìù Markdown Files',
            str(len(self.workspace_structure['markdown_files'])),
            'T√†i li·ªáu v√† h∆∞·ªõng d·∫´n',
        )
        table.add_row(
            '‚ùì Question Files',
            str(len(self.workspace_structure['question_files'])),
            'Ng√¢n h√†ng c√¢u h·ªèi',
        )
        table.add_row(
            'üêç Python Files',
            str(len(self.workspace_structure['python_files'])),
            'Source code v√† examples',
        )
        table.add_row(
            '‚öôÔ∏è Config Files',
            str(len(self.workspace_structure['config_files'])),
            'Configuration files',
        )

        console.print(table)

    def _select_folders_to_load(self) -> Optional[List[str]]:
        """Cho ph√©p user ch·ªçn folders ƒë·ªÉ load"""
        if not self.workspace_structure['folders']:
            return None

        # Extract unique folder names from full paths
        folder_names = set()
        for folder_path in self.workspace_structure['folders']:
            # Get relative folder names
            parts = Path(folder_path).parts
            if len(parts) > 1:  # Not root
                folder_names.add(parts[-1])  # Last part (folder name)

        folder_list = sorted(folder_names)

        if not folder_list:
            return None

        console.print(
            f'\n[bold yellow]üìÇ C√≥ {len(folder_list)} folders c√≥ th·ªÉ ch·ªçn:[/bold yellow]'
        )

        # Display options
        table = Table(show_header=True, header_style='bold magenta')
        table.add_column('S·ªë', style='cyan', width=5)
        table.add_column('Folder', style='white')
        table.add_column('M√¥ t·∫£', style='dim')

        folder_descriptions = {
            'getting-started': 'H∆∞·ªõng d·∫´n c∆° b·∫£n',
            'pipelines': 'C√°c pipeline chuy√™n bi·ªát',
            'text-classification': 'Ph√¢n lo·∫°i vƒÉn b·∫£n',
            'text-summarization': 'T√≥m t·∫Øt vƒÉn b·∫£n',
            'datasets': 'X·ª≠ l√Ω d·ªØ li·ªáu',
            '__pycache__': 'Cache files (kh√¥ng khuy·∫øn kh√≠ch)',
        }

        for i, folder in enumerate(folder_list, 1):
            description = folder_descriptions.get(folder, 'N·ªôi dung kh√°c')
            table.add_row(str(i), folder, description)

        table.add_row('0', '[ALL]', 'T·∫•t c·∫£ folders')

        console.print(table)

        # Get user choice
        try:
            choice = Prompt.ask(
                '\n[bold]Ch·ªçn folders (v√≠ d·ª•: 1,2,3 ho·∫∑c 0 cho t·∫•t c·∫£)[/bold]',
                default='0',
            )

            if choice == '0':
                console.print('[green]‚úì S·∫Ω n·∫°p t·∫•t c·∫£ folders[/green]')
                return None  # Load all

            # Parse selected folders
            selected_indices = [
                int(x.strip()) for x in choice.split(',') if x.strip().isdigit()
            ]
            selected_folders = [
                folder_list[i - 1]
                for i in selected_indices
                if 1 <= i <= len(folder_list)
            ]

            if selected_folders:
                console.print(f'[green]‚úì S·∫Ω n·∫°p: {", ".join(selected_folders)}[/green]')
                return selected_folders
            else:
                console.print(
                    '[yellow]‚ö† Kh√¥ng c√≥ l·ª±a ch·ªçn h·ª£p l·ªá, s·∫Ω n·∫°p t·∫•t c·∫£[/yellow]'
                )
                return None

        except (ValueError, KeyboardInterrupt):
            console.print('[yellow]‚ö† L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá, s·∫Ω n·∫°p t·∫•t c·∫£[/yellow]')
            return None

    def _display_loading_results(self):
        """Hi·ªÉn th·ªã k·∫øt qu·∫£ loading"""
        console.print('\n[bold green]‚úÖ ƒê√£ n·∫°p workspace th√†nh c√¥ng![/bold green]')

        # Knowledge statistics
        if self.knowledge_base:
            kb_stats = self._analyze_knowledge_base()

            stats_table = Table(
                title='üìä Th·ªëng k√™ Knowledge Base', title_style='bold green'
            )
            stats_table.add_column('Th√¥ng tin', style='cyan')
            stats_table.add_column('Gi√° tr·ªã', justify='right', style='white')

            stats_table.add_row('üìö T·ªïng t√†i li·ªáu', str(len(self.knowledge_base)))
            stats_table.add_row('üìù Markdown files', str(kb_stats['markdown_count']))
            stats_table.add_row('üêç Python files', str(kb_stats['python_count']))
            stats_table.add_row('üìÅ Folders', str(len(kb_stats['folders'])))
            stats_table.add_row('üîë Keywords', str(kb_stats['total_keywords']))
            stats_table.add_row(
                'üìÑ T·ªïng n·ªôi dung', f'{kb_stats["total_content_length"]:,} k√Ω t·ª±'
            )

            console.print(stats_table)

            # Top folders by content
            if kb_stats['folder_stats']:
                folder_table = Table(
                    title='üìÇ Top Folders theo n·ªôi dung', title_style='bold blue'
                )
                folder_table.add_column('Folder', style='cyan')
                folder_table.add_column('Files', justify='right', style='magenta')
                folder_table.add_column('Content Size', justify='right', style='white')

                for folder, stats in sorted(
                    kb_stats['folder_stats'].items(),
                    key=lambda x: x[1]['content_length'],
                    reverse=True,
                )[:5]:
                    folder_table.add_row(
                        folder,
                        str(stats['file_count']),
                        f'{stats["content_length"]:,} chars',
                    )

                console.print(folder_table)

        # Question statistics
        if self.questions:
            console.print(
                f'[bold yellow]‚ùì ƒê√£ n·∫°p {len(self.questions)} c√¢u h·ªèi t·ª´ {len(self.workspace_structure["question_files"])} files[/bold yellow]'
            )

    def _analyze_knowledge_base(self) -> Dict[str, Any]:
        """Ph√¢n t√≠ch knowledge base ƒë·ªÉ c√≥ th·ªëng k√™"""
        stats = {
            'markdown_count': 0,
            'python_count': 0,
            'folders': set(),
            'total_keywords': 0,
            'total_content_length': 0,
            'folder_stats': {},
        }

        for knowledge in self.knowledge_base:
            # Count by file type
            if knowledge.file_type == 'markdown':
                stats['markdown_count'] += 1
            elif knowledge.file_type == 'python':
                stats['python_count'] += 1

            # Collect folders
            stats['folders'].add(knowledge.folder)

            # Count keywords
            stats['total_keywords'] += len(knowledge.keywords)

            # Count content length
            stats['total_content_length'] += len(knowledge.content)

            # Folder statistics
            folder = knowledge.folder
            if folder not in stats['folder_stats']:
                stats['folder_stats'][folder] = {'file_count': 0, 'content_length': 0}

            stats['folder_stats'][folder]['file_count'] += 1
            stats['folder_stats'][folder]['content_length'] += len(knowledge.content)

        return stats

    def load_data(self, file_paths: List[str]):
        """T·∫£i d·ªØ li·ªáu t·ª´ c√°c file markdown (method c≈©, gi·ªØ ƒë·ªÉ backward compatibility)"""
        parser = MarkdownParser()

        with Progress(
            SpinnerColumn(),
            TextColumn('[progress.description]{task.description}'),
            console=console,
        ) as progress:
            task = progress.add_task('ƒêang t·∫£i d·ªØ li·ªáu...', total=len(file_paths))

            for file_path in file_paths:
                if not os.path.exists(file_path):
                    console.print(f'[red]File kh√¥ng t·ªìn t·∫°i: {file_path}[/red]')
                    continue

                progress.update(task, description=f'ƒêang x·ª≠ l√Ω {Path(file_path).name}')

                if 'question' in file_path.lower():
                    # File ch·ª©a c√¢u h·ªèi
                    questions = parser.parse_questions(file_path)
                    self.questions.extend(questions)
                    console.print(
                        f'[green]‚úì ƒê√£ t·∫£i {len(questions)} c√¢u h·ªèi t·ª´ {Path(file_path).name}[/green]'
                    )
                else:
                    # File ch·ª©a ki·∫øn th·ª©c
                    knowledge = parser.parse_knowledge(file_path)
                    if knowledge:
                        self.knowledge_base.append(knowledge)
                        console.print(
                            f'[green]‚úì ƒê√£ t·∫£i ki·∫øn th·ª©c t·ª´ {Path(file_path).name}[/green]'
                        )

                progress.advance(task)

        console.print(
            f'\n[bold green]T·ªïng c·ªông: {len(self.questions)} c√¢u h·ªèi v√† {len(self.knowledge_base)} t√†i li·ªáu ki·∫øn th·ª©c[/bold green]'
        )

    def start_interview(self):
        """B·∫Øt ƒë·∫ßu ph·ªèng v·∫•n"""
        if not self.questions:
            console.print('[red]Kh√¥ng c√≥ c√¢u h·ªèi n√†o ƒë·ªÉ ph·ªèng v·∫•n![/red]')
            return

        self.session_stats['start_time'] = datetime.now()
        self.session_stats['total_questions'] = len(self.questions)

        console.print(
            Panel.fit(
                '[bold blue]üéØ B·∫Øt ƒë·∫ßu ph·ªèng v·∫•n Hugging Face![/bold blue]\n'
                f'T·ªïng s·ªë c√¢u h·ªèi: {len(self.questions)}\n'
                "G√µ 'help' ƒë·ªÉ xem tr·ª£ gi√∫p, 'quit' ƒë·ªÉ tho√°t",
                title='AI Interview Agent',
                border_style='blue',
            )
        )

        # Shuffle questions for randomness

        random.shuffle(self.questions)

        for i, question in enumerate(self.questions, 1):
            console.print(f'\n[bold cyan]C√¢u h·ªèi {i}/{len(self.questions)}[/bold cyan]')

            if self.ask_question(question):
                self.score += 1
                self.session_stats['correct_answers'] += 1

        self.session_stats['end_time'] = datetime.now()
        self.show_final_results()

    def ask_question(self, question: Question) -> bool:
        """ƒê·∫∑t c√¢u h·ªèi v√† nh·∫≠n ph·∫£n h·ªìi"""
        self.current_question = question

        # Hi·ªÉn th·ªã c√¢u h·ªèi
        console.print(
            Panel(
                f'[bold]{question.title}[/bold]\n\n'
                f'[dim]{question.description}[/dim]\n\n'
                f'[yellow]{question.question}[/yellow]',
                title=f'Question ID: {question.id}',
                border_style='yellow',
            )
        )

        # Hi·ªÉn th·ªã c√°c l·ª±a ch·ªçn
        table = Table(show_header=True, header_style='bold magenta')
        table.add_column('L·ª±a ch·ªçn', style='cyan', width=10)
        table.add_column('N·ªôi dung', style='white')

        for i, option in enumerate(question.options, 1):
            table.add_row(f'({i})', option)

        console.print(table)

        # Nh·∫≠n ph·∫£n h·ªìi t·ª´ user
        while True:
            try:
                response = Prompt.ask(
                    "\n[bold]Ch·ªçn ƒë√°p √°n c·ªßa b·∫°n (1-4) ho·∫∑c g√µ 'help'/'quit'[/bold]",
                    choices=['1', '2', '3', '4', 'help', 'quit', 'h', 'q'],
                    show_choices=False,
                )

                if response.lower() in ['quit', 'q']:
                    console.print('[red]Tho√°t ph·ªèng v·∫•n...[/red]')
                    sys.exit(0)

                if response.lower() in ['help', 'h']:
                    self.show_help()
                    continue

                # Chuy·ªÉn ƒë·ªïi l·ª±a ch·ªçn th√†nh text
                choice_index = int(response) - 1
                if 0 <= choice_index < len(question.options):
                    user_answer = question.options[choice_index]
                    return self.check_answer(user_answer, question)
                else:
                    console.print('[red]L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá![/red]')
                    continue

            except (ValueError, KeyboardInterrupt):
                console.print('[red]L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá![/red]')
                continue

    def check_answer(self, user_answer: str, question: Question) -> bool:
        """Ki·ªÉm tra ƒë√°p √°n v√† ƒë∆∞a ra ph·∫£n h·ªìi"""
        is_correct = user_answer.strip() == question.correct_answer.strip()

        if is_correct:
            console.print(
                Panel(
                    f'[bold green]üéâ Ch√≠nh x√°c![/bold green]\n\n'
                    f'[green]Gi·∫£i th√≠ch:[/green] {question.explanation}',
                    title='K·∫øt qu·∫£',
                    border_style='green',
                )
            )
        else:
            console.print(
                Panel(
                    f'[bold red]‚ùå Sai r·ªìi![/bold red]\n\n'
                    f'[red]ƒê√°p √°n ƒë√∫ng:[/red] {question.correct_answer}\n'
                    f'[red]ƒê√°p √°n c·ªßa b·∫°n:[/red] {user_answer}\n\n'
                    f'[yellow]Gi·∫£i th√≠ch:[/yellow] {question.explanation}',
                    title='K·∫øt qu·∫£',
                    border_style='red',
                )
            )

        # Hi·ªÉn th·ªã ki·∫øn th·ª©c li√™n quan
        self.show_related_knowledge(question)

        # H·ªèi c√≥ mu·ªën ti·∫øp t·ª•c kh√¥ng
        if not Confirm.ask('\n[bold]Ti·∫øp t·ª•c c√¢u h·ªèi ti·∫øp theo?[/bold]', default=True):
            console.print('[yellow]K·∫øt th√∫c ph·ªèng v·∫•n...[/yellow]')
            self.show_final_results()
            sys.exit(0)

        return is_correct

    def show_related_knowledge(self, question: Question):
        """Hi·ªÉn th·ªã ki·∫øn th·ª©c li√™n quan ƒë·∫øn c√¢u h·ªèi"""
        # T√¨m ki·∫øn th·ª©c li√™n quan d·ª±a tr√™n t·ª´ kh√≥a
        related_knowledge = []
        question_keywords = (
            question.title.lower().split() + question.question.lower().split()
        )

        for knowledge in self.knowledge_base:
            for keyword in question_keywords:
                if (
                    keyword in knowledge.keywords
                    or keyword in knowledge.content.lower()
                ):
                    related_knowledge.append(knowledge)
                    break

        if related_knowledge:
            console.print('\n[bold blue]üìö Ki·∫øn th·ª©c li√™n quan:[/bold blue]')
            for i, knowledge in enumerate(
                related_knowledge[:2], 1
            ):  # Ch·ªâ hi·ªÉn th·ªã 2 t√†i li·ªáu ƒë·∫ßu
                console.print(
                    f'[dim]{i}. {knowledge.title} (t·ª´ {Path(knowledge.source_file).name})[/dim]'
                )

    def show_help(self):
        """Hi·ªÉn th·ªã tr·ª£ gi√∫p"""
        help_text = """
        [bold blue]üîß H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:[/bold blue]

        [yellow]C√°c l·ªánh c√≥ s·∫µn:[/yellow]
        ‚Ä¢ 1-4: Ch·ªçn ƒë√°p √°n
        ‚Ä¢ help (h): Hi·ªÉn th·ªã tr·ª£ gi√∫p n√†y
        ‚Ä¢ quit (q): Tho√°t ch∆∞∆°ng tr√¨nh

        [yellow]C√°ch th·ª©c ho·∫°t ƒë·ªông:[/yellow]
        ‚Ä¢ Ch·ªçn s·ªë t∆∞∆°ng ·ª©ng v·ªõi ƒë√°p √°n b·∫°n cho l√† ƒë√∫ng
        ‚Ä¢ H·ªá th·ªëng s·∫Ω ki·ªÉm tra v√† ƒë∆∞a ra gi·∫£i th√≠ch
        ‚Ä¢ ƒêi·ªÉm s·ªë v√† th·ªëng k√™ s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã cu·ªëi phi√™n

        [yellow]M·∫πo:[/yellow]
        ‚Ä¢ ƒê·ªçc k·ªπ m√¥ t·∫£ c√¢u h·ªèi tr∆∞·ªõc khi ch·ªçn
        ‚Ä¢ Ch√∫ √Ω ƒë·∫øn t·ª´ kh√≥a quan tr·ªçng
        ‚Ä¢ S·ª≠ d·ª•ng ki·∫øn th·ª©c t·ª´ t√†i li·ªáu ƒë√£ t·∫£i
        """
        console.print(Panel(help_text, title='Tr·ª£ gi√∫p', border_style='blue'))

    def show_final_results(self):
        """Hi·ªÉn th·ªã k·∫øt qu·∫£ cu·ªëi c√πng"""
        if self.session_stats['start_time'] and self.session_stats['end_time']:
            duration = self.session_stats['end_time'] - self.session_stats['start_time']
            duration_str = f'{duration.total_seconds():.1f} gi√¢y'
        else:
            duration_str = 'N/A'

        total = self.session_stats['total_questions']
        correct = self.session_stats['correct_answers']
        percentage = (correct / total * 100) if total > 0 else 0

        # ƒê√°nh gi√° k·∫øt qu·∫£
        if percentage >= 80:
            grade = 'Xu·∫•t s·∫Øc! üåü'
            color = 'green'
        elif percentage >= 60:
            grade = 'Kh√° t·ªët! üëç'
            color = 'yellow'
        elif percentage >= 40:
            grade = 'C·∫ßn c·∫£i thi·ªán üìö'
            color = 'orange'
        else:
            grade = 'C·∫ßn h·ªçc th√™m üí™'
            color = 'red'

        result_table = Table(title='üéØ K·∫øt qu·∫£ ph·ªèng v·∫•n', title_style='bold blue')
        result_table.add_column('Ch·ªâ s·ªë', style='cyan', width=20)
        result_table.add_column('Gi√° tr·ªã', style='white')

        result_table.add_row('T·ªïng c√¢u h·ªèi', str(total))
        result_table.add_row('C√¢u tr·∫£ l·ªùi ƒë√∫ng', str(correct))
        result_table.add_row('T·ª∑ l·ªá ch√≠nh x√°c', f'{percentage:.1f}%')
        result_table.add_row('Th·ªùi gian', duration_str)
        result_table.add_row('ƒê√°nh gi√°', f'[{color}]{grade}[/{color}]')

        console.print('\n')
        console.print(result_table)

        # L·ªùi khuy√™n
        console.print(
            Panel(
                self.get_advice(percentage), title='üí° L·ªùi khuy√™n', border_style='blue'
            )
        )

    def get_advice(self, percentage: float) -> str:
        """ƒê∆∞a ra l·ªùi khuy√™n d·ª±a tr√™n k·∫øt qu·∫£"""
        if percentage >= 80:
            return '[green]B·∫°n ƒë√£ c√≥ ki·∫øn th·ª©c r·∫•t t·ªët v·ªÅ Hugging Face! Ti·∫øp t·ª•c duy tr√¨ v√† kh√°m ph√° c√°c t√≠nh nƒÉng n√¢ng cao.[/green]'
        elif percentage >= 60:
            return '[yellow]B·∫°n ƒë√£ n·∫Øm ƒë∆∞·ª£c nh·ªØng ki·∫øn th·ª©c c∆° b·∫£n. H√£y t·∫≠p trung v√†o nh·ªØng ph·∫ßn c√≤n thi·∫øu v√† th·ª±c h√†nh th√™m.[/yellow]'
        elif percentage >= 40:
            return '[orange]B·∫°n c·∫ßn ƒë·ªçc l·∫°i t√†i li·ªáu v√† th·ª±c h√†nh th√™m. T·∫≠p trung v√†o c√°c kh√°i ni·ªám c∆° b·∫£n tr∆∞·ªõc.[/orange]'
        else:
            return '[red]H√£y b·∫Øt ƒë·∫ßu t·ª´ nh·ªØng ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ Hugging Face. ƒê·ªçc documentation v√† l√†m theo tutorial.[/red]'


class ChatMode:
    """Ch·∫ø ƒë·ªô chat t∆∞∆°ng t√°c v·ªõi AI Ollama"""

    def __init__(self, agent: InterviewAgent):
        self.agent = agent
        self.conversation_history = []
        self.gemini_ai = GeminiAI()
        self.use_ai = self.gemini_ai.is_available

        # Initialize Hybrid AI system safely
        self._initialize_hybrid_ai_safely()

    def _initialize_hybrid_ai_safely(self):
        """Kh·ªüi t·∫°o Hybrid AI m·ªôt c√°ch an to√†n"""
        try:
            # Th·ª≠ kh·ªüi t·∫°o v·ªõi Gemini
            if self.gemini_ai.is_available:
                # T·∫°o mock Ollama AI cho testing
                class MockOllamaAI:
                    def __init__(self):
                        self.model_name = 'llama3:8b'
                        self.is_available = False

                    def generate_response(
                        self, prompt: str, context: str = '', max_tokens: int = 500
                    ) -> AIResponse:
                        return AIResponse(
                            content='Mock response t·ª´ Ollama (ch∆∞a kh·∫£ d·ª•ng)',
                            source='mock',
                            confidence=0.5,
                        )

                # T·∫°o hybrid AI v·ªõi mock Ollama
                self.hybrid_ai = type(
                    'HybridAI',
                    (),
                    {
                        'gemini_ai': self.gemini_ai,
                        'ollama_ai': MockOllamaAI(),
                        '_auto_optimize_ollama': lambda: {
                            'status': 'mock',
                            'message': 'Demo mode',
                        },
                        '_learn_from_gemini': lambda q: console.print(
                            '[blue]üìö Mock learning session[/blue]'
                        ),
                        'get_training_stats': lambda: {
                            'total_gemini_calls': 0,
                            'total_ollama_calls': 0,
                            'learning_sessions': 0,
                            'current_model': 'Mock Model',
                            'last_optimization': 'Never',
                        },
                    },
                )()

                console.print(
                    '[green]‚úÖ Hybrid AI System initialized (Mock mode)[/green]'
                )
                return True

        except Exception as e:
            console.print(f'[yellow]‚ö†Ô∏è Hybrid AI initialization failed: {e}[/yellow]')
            self.hybrid_ai = None
            return False

    def start_chat(self):
        """B·∫Øt ƒë·∫ßu ch·∫ø ƒë·ªô chat v·ªõi Hybrid AI System"""
        ai_status = (
            'üöÄ Hybrid AI (Gemini + Ollama)' if self.use_ai else '‚ùå AI kh√¥ng kh·∫£ d·ª•ng'
        )
        console.print(
            Panel.fit(
                f'[bold green]üí¨ Enhanced AI Chat Assistant ({ai_status})[/bold green]\n'
                'üéØ Chuy√™n gia ph·ªèng v·∫•n Hugging Face & Machine Learning\n'
                "G√µ 'quit' ƒë·ªÉ tho√°t, 'interview' ƒë·ªÉ chuy·ªÉn sang ch·∫ø ƒë·ªô ph·ªèng v·∫•n\n"
                "G√µ 'stats' ƒë·ªÉ xem th·ªëng k√™, 'train' ƒë·ªÉ t·ªëi ∆∞u model, 'help' ƒë·ªÉ xem tr·ª£ gi√∫p\n"
                'Commands: stats | train | metrics | learn | help | interview | quit',
                title='ü§ñ Hybrid AI Interview Expert',
                border_style='green',
            )
        )

        if not self.use_ai:
            console.print(
                '[red]‚ö†Ô∏è AI kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra API key trong .env[/red]'
            )
            return

        while True:
            try:
                user_input = Prompt.ask('\n[bold blue]B·∫°n[/bold blue]')

                if user_input.lower() in ['quit', 'q', 'exit']:
                    console.print('[green]T·∫°m bi·ªát! üëã[/green]')
                    break

                if user_input.lower() in ['interview', 'test']:
                    console.print('[yellow]Chuy·ªÉn sang ch·∫ø ƒë·ªô ph·ªèng v·∫•n...[/yellow]')
                    self.agent.start_interview()
                    continue

                if user_input.lower() in ['stats', 'statistics']:
                    self._show_workspace_stats()
                    continue

                if user_input.lower() in ['help', 'h']:
                    self._show_chat_help()
                    continue

                if user_input.lower() == 'train':
                    console.print('\n[blue]üîß B·∫Øt ƒë·∫ßu auto-optimization...[/blue]')
                    if hasattr(self, 'hybrid_ai'):
                        result = self.hybrid_ai._auto_optimize_ollama()  # type: ignore
                        self._show_training_result(result)
                    else:
                        console.print('[yellow]‚ö†Ô∏è Hybrid AI ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o[/yellow]')
                    continue

                if user_input.lower() == 'metrics':
                    self._show_training_metrics()
                    continue

                if user_input.lower() == 'learn':
                    console.print('\n[blue]üìö B·∫Øt ƒë·∫ßu session h·ªçc t·ª´ Gemini...[/blue]')
                    if hasattr(self, 'hybrid_ai'):
                        self.hybrid_ai._learn_from_gemini(user_input)  # type: ignore
                    else:
                        console.print('[yellow]‚ö†Ô∏è Hybrid AI ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o[/yellow]')
                    continue

                # X·ª≠ l√Ω c√¢u h·ªèi v·ªõi AI
                response = self.process_question_with_ai(user_input)

                console.print('\n[bold green]ü§ñ Hybrid AI Expert[/bold green]')
                console.print(Panel(response, border_style='green'))

            except KeyboardInterrupt:
                console.print('\n[green]T·∫°m bi·ªát! üëã[/green]')
                break

    def _show_workspace_stats(self):
        """Hi·ªÉn th·ªã th·ªëng k√™ workspace"""
        if not self.agent.knowledge_base:
            console.print('[yellow]üìä Ch∆∞a c√≥ workspace n√†o ƒë∆∞·ª£c n·∫°p[/yellow]')
            return

        kb_stats = self.agent._analyze_knowledge_base()

        stats_table = Table(title='üìä Workspace Statistics', title_style='bold cyan')
        stats_table.add_column('Metric', style='yellow')
        stats_table.add_column('Value', justify='right', style='white')

        stats_table.add_row('üìö Total Documents', str(len(self.agent.knowledge_base)))
        stats_table.add_row('üìù Markdown Files', str(kb_stats['markdown_count']))
        stats_table.add_row('üêç Python Files', str(kb_stats['python_count']))
        stats_table.add_row('üìÅ Folders', str(len(kb_stats['folders'])))
        stats_table.add_row('üîë Total Keywords', str(kb_stats['total_keywords']))
        stats_table.add_row(
            'üìÑ Content Size', f'{kb_stats["total_content_length"]:,} chars'
        )
        stats_table.add_row('‚ùì Questions Available', str(len(self.agent.questions)))

        console.print(stats_table)

        # AI readiness status
        ai_table = Table(title='ü§ñ AI Capabilities', title_style='bold green')
        ai_table.add_column('Feature', style='cyan')
        ai_table.add_column('Status', style='white')

        ai_table.add_row(
            'Gemini AI',
            '‚úÖ Ready' if self.gemini_ai.is_available else '‚ùå Not Available',
        )
        ai_table.add_row('Model', self.gemini_ai.model_name)
        ai_table.add_row('Context Fusion', 'üöÄ Advanced Knowledge Integration')
        ai_table.add_row('Confidence Scoring', 'üìä Multi-factor Analysis')

        console.print(ai_table)

    def _show_chat_help(self):
        """Hi·ªÉn th·ªã tr·ª£ gi√∫p cho chat mode"""
        help_text = """
[bold cyan]üöÄ Enhanced Gemini AI Chat Assistant[/bold cyan]

[yellow]üìã Available Commands:[/yellow]
‚Ä¢ [bold]interview[/bold] - Chuy·ªÉn sang ch·∫ø ƒë·ªô ph·ªèng v·∫•n
‚Ä¢ [bold]stats[/bold] - Hi·ªÉn th·ªã th·ªëng k√™ workspace
‚Ä¢ [bold]help[/bold] - Hi·ªÉn th·ªã tr·ª£ gi√∫p n√†y
‚Ä¢ [bold]quit[/bold] - Tho√°t ch∆∞∆°ng tr√¨nh

[yellow]üéØ AI Capabilities:[/yellow]
‚Ä¢ [green]Advanced Knowledge Fusion[/green] - K·∫øt h·ª£p workspace + Gemini knowledge
‚Ä¢ [green]Smart Context Analysis[/green] - Ph√¢n t√≠ch intent v√† relevance
‚Ä¢ [green]Multi-source Integration[/green] - S·ª≠ d·ª•ng c·∫£ local v√† cloud knowledge
‚Ä¢ [green]Professional Interview Focus[/green] - T·ªëi ∆∞u cho m·ª•c ƒë√≠ch ph·ªèng v·∫•n

[yellow]üí° Tips for Best Results:[/yellow]
‚Ä¢ H·ªèi c√¢u h·ªèi c·ª• th·ªÉ v·ªÅ Hugging Face, ML, Python
‚Ä¢ Y√™u c·∫ßu examples, code samples, best practices
‚Ä¢ H·ªèi v·ªÅ troubleshooting v√† real-world applications
‚Ä¢ S·ª≠ d·ª•ng context t·ª´ workspace ƒë·ªÉ c√≥ c√¢u tr·∫£ l·ªùi ch√≠nh x√°c nh·∫•t

[yellow]üöÄ Powered by:[/yellow]
‚Ä¢ Google Gemini 2.0 Flash - Latest AI model
‚Ä¢ Workspace Knowledge Integration
‚Ä¢ Advanced Prompt Engineering
"""
        console.print(Panel(help_text, title='üí¨ Chat Help', border_style='cyan'))

    def _build_context(self, question: str) -> str:
        """X√¢y d·ª±ng context t·ª´ knowledge base cho AI"""
        question_lower = question.lower()
        relevant_knowledge = []

        # T√¨m ki·∫øn th·ª©c li√™n quan
        for knowledge in self.agent.knowledge_base:
            relevance_score = 0

            # Ki·ªÉm tra keywords
            for keyword in knowledge.keywords:
                if keyword in question_lower:
                    relevance_score += 2

            # Ki·ªÉm tra content
            content_lower = knowledge.content.lower()
            for word in question_lower.split():
                if word in content_lower:
                    relevance_score += 1

            if relevance_score > 0:
                relevant_knowledge.append((relevance_score, knowledge))

        # S·∫Øp x·∫øp theo relevance score
        relevant_knowledge.sort(key=lambda x: x[0], reverse=True)

        # T·∫°o context
        context = ''
        for _score, knowledge in relevant_knowledge[:3]:  # L·∫•y top 3
            context += f'## {knowledge.title}\n'
            context += f'Source: {Path(knowledge.source_file).name}\n'
            context += f'Content: {knowledge.content[:800]}...\n\n'

        return (
            context if context else 'Kh√¥ng c√≥ th√¥ng tin li√™n quan trong knowledge base.'
        )

    def process_question_with_ai(self, question: str) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi v·ªõi AI Ollama"""
        try:
            # T·∫°o context t·ª´ knowledge base
            context = self._build_context(question)

            # G·ªçi Gemini AI
            with console.status(
                '[bold green]ü§ñ Gemini AI ƒëang ph√¢n t√≠ch...', spinner='dots'
            ):
                ai_response = self.gemini_ai.generate_response(question, context)

            # Format response v·ªõi template ƒë·∫πp
            return self._format_ai_response(ai_response, question)

        except Exception as e:
            console.print(f'[red]L·ªói AI: {e}[/red]')
            return self.process_question_rule_based(question)

    def _format_ai_response(self, ai_response: AIResponse, question: str) -> str:
        """Format AI response v·ªõi template ƒë·∫πp v√† clean"""
        lines = []

        # Header v·ªõi confidence
        confidence_emoji = self._get_confidence_emoji(ai_response.confidence)
        lines.append(
            f'ü§ñ AI Analysis {confidence_emoji} ({ai_response.confidence:.0%} confidence)'
        )
        lines.append('')

        # Main content - l√†m s·∫°ch v√† format
        clean_content = self._clean_ai_content(ai_response.content)
        if clean_content:
            lines.append('üìã Answer:')
            lines.append('‚îÄ' * 50)
            lines.extend(self._format_content_lines(clean_content))
            lines.append('')

        # Thinking process (n·∫øu c√≥) - compact format
        if ai_response.thinking_process:
            thinking_clean = self._clean_ai_content(ai_response.thinking_process)
            if thinking_clean and len(thinking_clean) > 20:  # Ch·ªâ hi·ªán n·∫øu c√≥ n·ªôi dung
                lines.append('üí≠ AI Reasoning:')
                lines.append('‚îÄ' * 30)
                # R√∫t g·ªçn thinking process
                thinking_summary = self._summarize_thinking(thinking_clean)
                lines.append(f'   {thinking_summary}')
                lines.append('')

        # Footer v·ªõi source info
        if ai_response.source == 'ollama':
            lines.append('üîç Analysis based on:')
            lines.append(
                f'   ‚Ä¢ Knowledge Base: {len(self.agent.knowledge_base)} documents'
            )
            lines.append('   ‚Ä¢ AI Model: Ollama Llama3')

        return '\n'.join(lines)

    def _get_confidence_emoji(self, confidence: float) -> str:
        """L·∫•y emoji ph√π h·ª£p v·ªõi confidence level"""
        if confidence >= 0.8:
            return 'üéØ'  # High confidence
        elif confidence >= 0.6:
            return '‚úÖ'  # Good confidence
        elif confidence >= 0.4:
            return '‚ö†Ô∏è'  # Medium confidence
        else:
            return '‚ùì'  # Low confidence

    def _clean_ai_content(self, content: str) -> str:
        """L√†m s·∫°ch content AI, lo·∫°i b·ªè markdown v√† formatting kh√¥ng c·∫ßn thi·∫øt"""
        if not content:
            return ''

        # Lo·∫°i b·ªè markdown formatting
        content = re.sub(r'\*\*(.*?)\*\*', r'\1', content)  # **bold** -> bold
        content = re.sub(r'\*(.*?)\*', r'\1', content)  # *italic* -> italic
        content = re.sub(r'`(.*?)`', r'\1', content)  # `code` -> code
        content = re.sub(r'#{1,6}\s*', '', content)  # headings
        content = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', content)  # links

        # L√†m s·∫°ch c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát - C·∫®N TH·∫¨N KH√îNG L·∫∂P
        # Ch·ªâ chu·∫©n h√≥a c√°c d·∫•u bullet ·ªü ƒë·∫ßu d√≤ng
        content = re.sub(r'^[\s]*[-\*]\s+', '‚Ä¢ ', content, flags=re.MULTILINE)
        content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)  # Lo·∫°i b·ªè line breaks th·ª´a

        # Lo·∫°i b·ªè c√°c th·∫ª thinking
        content = re.sub(r'<thinking>.*?</thinking>', '', content, flags=re.DOTALL)

        return content.strip()

    def _format_content_lines(self, content: str) -> List[str]:
        """Format content th√†nh c√°c d√≤ng ƒë·∫πp v·ªõi indentation"""
        lines = content.split('\n')
        formatted = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # Bullet points
            if line.startswith('‚Ä¢'):
                formatted.append(f'   {line}')
            # Numbered lists
            elif re.match(r'^\d+\.', line):
                formatted.append(f'   {line}')
            # Headers or important lines
            elif line.isupper() or line.endswith(':'):
                formatted.append(f'\n   {line}')
            # Regular content
            else:
                # Wrap long lines
                if len(line) > 80:
                    wrapped = self._wrap_text(line, 80)
                    for wrapped_line in wrapped:
                        formatted.append(f'   {wrapped_line}')
                else:
                    formatted.append(f'   {line}')

        return formatted

    def _wrap_text(self, text: str, width: int) -> List[str]:
        """Wrap text ƒë·ªÉ kh√¥ng qu√° d√†i"""
        words = text.split()
        lines = []
        current_line = []
        current_length = 0

        for word in words:
            if current_length + len(word) + 1 <= width:
                current_line.append(word)
                current_length += len(word) + 1
            else:
                if current_line:
                    lines.append(' '.join(current_line))
                current_line = [word]
                current_length = len(word)

        if current_line:
            lines.append(' '.join(current_line))

        return lines

    def _summarize_thinking(self, thinking: str) -> str:
        """T√≥m t·∫Øt thinking process ƒë·ªÉ hi·ªÉn th·ªã g·ªçn"""
        # L·∫•y c√¢u ƒë·∫ßu ti√™n ho·∫∑c 100 k√Ω t·ª± ƒë·∫ßu
        sentences = thinking.split('.')
        if sentences and len(sentences[0]) > 20:
            summary = sentences[0].strip()
            if len(summary) > 100:
                summary = summary[:100] + '...'
            return summary
        else:
            return thinking[:100] + '...' if len(thinking) > 100 else thinking

    def process_question_rule_based(self, question: str) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi theo rule-based (ph∆∞∆°ng ph√°p c≈©)"""
        return self.process_question(question)

    def process_question(self, question: str) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi v√† tr·∫£ l·ªùi d·ª±a tr√™n knowledge base"""
        question_lower = question.lower()

        # T√¨m ki·∫øn th·ª©c li√™n quan
        relevant_knowledge = []
        for knowledge in self.agent.knowledge_base:
            for keyword in knowledge.keywords:
                if keyword in question_lower:
                    relevant_knowledge.append(knowledge)
                    break

        # N·∫øu kh√¥ng t√¨m th·∫•y ki·∫øn th·ª©c li√™n quan, t√¨m theo content
        if not relevant_knowledge:
            for knowledge in self.agent.knowledge_base:
                if any(
                    word in knowledge.content.lower() for word in question_lower.split()
                ):
                    relevant_knowledge.append(knowledge)

        if relevant_knowledge:
            return self._format_rule_based_response(relevant_knowledge, question)
        else:
            return self._format_no_results_response()

    def _format_rule_based_response(
        self, relevant_knowledge: List[Knowledge], question: str
    ) -> str:
        """Format rule-based response v·ªõi template ƒë·∫πp"""
        lines = []

        # Header
        lines.append('üìö Knowledge Base Search ‚úÖ')
        lines.append('')

        # Main content
        lines.append('üìã Found Information:')
        lines.append('‚îÄ' * 50)

        for i, knowledge in enumerate(
            relevant_knowledge[:2], 1
        ):  # Ch·ªâ l·∫•y 2 t√†i li·ªáu ƒë·∫ßu
            lines.append(f'\nÔøΩ Source {i}: {self._clean_markdown(knowledge.title)}')
            lines.append('‚îÄ' * 30)

            # S·ª≠ d·ª•ng smart search ƒë·ªÉ t√¨m n·ªôi dung li√™n quan
            smart_results = self._smart_search(question, knowledge)

            if smart_results:
                # Hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ki·∫øm th√¥ng minh
                for result in smart_results[:3]:  # Gi·ªõi h·∫°n 3 k·∫øt qu·∫£
                    cleaned_result = self._clean_markdown(result)
                    if cleaned_result and len(cleaned_result) > 10:
                        # Format v·ªõi indentation - lo·∫°i b·ªè bullet c√≥ s·∫µn
                        formatted_result = self._format_single_result(cleaned_result)
                        # Lo·∫°i b·ªè bullet ·ªü ƒë·∫ßu n·∫øu c√≥
                        if formatted_result.startswith('‚Ä¢ '):
                            formatted_result = formatted_result[2:]
                        lines.append(f'   ‚Ä¢ {formatted_result}')
            else:
                # Fallback: extract key points
                key_points = self._extract_key_points(knowledge.content)
                if key_points:
                    for point in key_points[:3]:  # Gi·ªõi h·∫°n 3 ƒëi·ªÉm
                        lines.append(f'   ‚Ä¢ {point}')
                else:
                    # Final fallback: clean content summary
                    summary = self._create_summary(knowledge.content)
                    lines.append(f'   {summary}')

            lines.append(f'\n   üìÅ From: {Path(knowledge.source_file).name}')

        # Footer
        lines.append('')
        lines.append('üîç Search based on:')
        lines.append('   ‚Ä¢ Keyword matching and content analysis')
        lines.append(f'   ‚Ä¢ Knowledge Base: {len(self.agent.knowledge_base)} documents')

        return '\n'.join(lines)

    def _format_no_results_response(self) -> str:
        """Format response khi kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£"""
        lines = []

        lines.append('üìö Knowledge Base Search ‚ùå')
        lines.append('')
        lines.append('üìã No Direct Match Found')
        lines.append('‚îÄ' * 50)
        lines.append('')
        lines.append('üí° Suggestions:')
        lines.append('   ‚Ä¢ Try asking about: Hugging Face, Models, Hub, API')
        lines.append("   ‚Ä¢ Switch to interview mode: type 'interview'")
        lines.append("   ‚Ä¢ Toggle AI mode: type 'ai'")
        lines.append('')
        lines.append('üîç Available Resources:')
        lines.append(f'   ‚Ä¢ Knowledge Base: {len(self.agent.knowledge_base)} documents')
        lines.append(f'   ‚Ä¢ Question Bank: {len(self.agent.questions)} questions')

        return '\n'.join(lines)

    def _format_single_result(self, result: str) -> str:
        """Format m·ªôt k·∫øt qu·∫£ t√¨m ki·∫øm"""
        # Lo·∫°i b·ªè k√Ω t·ª± th·ª´a v√† format ƒë·∫πp
        result = result.strip()

        # N·∫øu qu√° d√†i, c·∫Øt ng·∫Øn
        if len(result) > 120:
            result = result[:120] + '...'

        return result

    def _create_summary(self, content: str) -> str:
        """T·∫°o summary ng·∫Øn g·ªçn t·ª´ content"""
        # L·∫•y c√¢u ƒë·∫ßu ti√™n ho·∫∑c ƒëo·∫°n ƒë·∫ßu
        sentences = content.split('.')
        if sentences and len(sentences[0].strip()) > 20:
            summary = sentences[0].strip()
            if len(summary) > 150:
                summary = summary[:150] + '...'
            return summary
        else:
            # Fallback: l·∫•y ƒëo·∫°n ƒë·∫ßu
            paragraphs = content.split('\n\n')
            if paragraphs:
                first_para = paragraphs[0].strip()
                if len(first_para) > 200:
                    first_para = first_para[:200] + '...'
                return self._clean_markdown(first_para)

        return 'Content available but requires specific keywords to search.'

    def _clean_markdown(self, text: str) -> str:
        """Lo·∫°i b·ªè c√°c k√Ω t·ª± markdown formatting"""
        if not text:
            return ''

        # Lo·∫°i b·ªè markdown formatting
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # **bold** -> bold
        text = re.sub(r'\*(.*?)\*', r'\1', text)  # *italic* -> italic
        text = re.sub(r'`(.*?)`', r'\1', text)  # `code` -> code
        text = re.sub(r'#{1,6}\s*', '', text)  # ## heading -> heading
        text = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', text)  # [text](url) -> text
        text = re.sub(
            r'^\s*[-*+]\s*', '‚Ä¢ ', text, flags=re.MULTILINE
        )  # - item -> ‚Ä¢ item

        return text.strip()

    def _format_content(self, content: str) -> str:
        """Format n·ªôi dung ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp h∆°n"""
        lines = content.split('\n')
        formatted_lines = []

        for line in lines:
            line = line.strip()
            if line:
                if line.startswith('‚Ä¢'):
                    formatted_lines.append(line)
                else:
                    formatted_lines.append(f'{line}')

        return '\n'.join(formatted_lines[:4])  # Gi·ªõi h·∫°n 4 d√≤ng

    def _smart_search(self, question: str, knowledge: Knowledge) -> List[str]:
        """T√¨m ki·∫øm th√¥ng minh trong knowledge base"""
        question_words = set(question.lower().split())
        lines = knowledge.content.split('\n')
        scored_lines = []

        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue

            # T√≠nh ƒëi·ªÉm relevance
            line_words = set(line.lower().split())
            score = len(question_words.intersection(line_words))

            # Bonus ƒëi·ªÉm cho d√≤ng ch·ª©a t·ª´ kh√≥a quan tr·ªçng
            if any(
                keyword in line.lower()
                for keyword in ['hugging face', 'model', 'api', 'hub']
            ):
                score += 2

            if score > 0:
                scored_lines.append((score, line))

        # Sort theo ƒëi·ªÉm v√† l·∫•y top results
        scored_lines.sort(key=lambda x: x[0], reverse=True)
        return [line for score, line in scored_lines[:5]]

    def _extract_key_points(self, content: str) -> List[str]:
        """Tr√≠ch xu·∫•t c√°c ƒëi·ªÉm ch√≠nh t·ª´ n·ªôi dung"""
        lines = content.split('\n')
        key_points = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # T√¨m c√°c bullet points
            if line.startswith(('- ', '‚Ä¢ ', '* ')):
                cleaned = self._clean_markdown(line[2:].strip())
                if cleaned:
                    key_points.append(cleaned)

            # T√¨m c√°c heading quan tr·ªçng
            elif line.startswith('###'):
                cleaned = self._clean_markdown(line[3:].strip())
                if cleaned:
                    key_points.append(f'üìå {cleaned}')

        return key_points[:6]  # Gi·ªõi h·∫°n 6 ƒëi·ªÉm ch√≠nh

    def _show_training_result(self, result: Dict[str, Any]):
        """Hi·ªÉn th·ªã k·∫øt qu·∫£ training/optimization"""
        if result.get('status') == 'optimized':
            console.print('\n[green]‚úÖ Model optimization ho√†n th√†nh![/green]')

            # T·∫°o b·∫£ng k·∫øt qu·∫£
            results_table = Table(
                title='üìä Optimization Results', title_style='bold green'
            )
            results_table.add_column('Metric', style='cyan')
            results_table.add_column('Value', style='white')

            results_table.add_row(
                'Previous Accuracy', f'{result.get("previous_accuracy", 0):.1%}'
            )
            results_table.add_row(
                'New Accuracy', f'{result.get("new_accuracy", 0):.1%}'
            )
            results_table.add_row(
                'Training Samples', str(result.get('training_samples', 0))
            )
            results_table.add_row(
                'Optimization Time', f'{result.get("optimization_time", 0):.1f}s'
            )

            console.print(results_table)

        elif result.get('status') == 'no_optimization_needed':
            console.print(
                f'\n[yellow]‚úÖ Model ƒë√£ t·ªëi ∆∞u (Accuracy: {result.get("current_accuracy", 0):.1%})[/yellow]'
            )

        elif result.get('status') == 'error':
            console.print(
                f'\n[red]‚ùå L·ªói optimization: {result.get("error", "Unknown error")}[/red]'
            )
        else:
            console.print(f'\n[blue]üìã Training Result: {result}[/blue]')

    def _show_training_metrics(self):
        """Hi·ªÉn th·ªã metrics c·ªßa training system"""
        if not hasattr(self, 'hybrid_ai') or not self.hybrid_ai:
            console.print('[yellow]‚ö†Ô∏è Hybrid AI system ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o[/yellow]')
            return

        try:
            stats = self.hybrid_ai.get_training_stats()  # type: ignore

            # T·∫°o b·∫£ng metrics
            metrics_table = Table(title='üìà Training Metrics', title_style='bold blue')
            metrics_table.add_column('Metric', style='cyan')
            metrics_table.add_column('Value', style='white')

            metrics_table.add_row(
                'Gemini API Calls', str(stats.get('total_gemini_calls', 0))
            )
            metrics_table.add_row(
                'Ollama API Calls', str(stats.get('total_ollama_calls', 0))
            )
            metrics_table.add_row(
                'Learning Sessions', str(stats.get('learning_sessions', 0))
            )
            metrics_table.add_row('Current Model', stats.get('current_model', 'N/A'))
            metrics_table.add_row(
                'Last Optimization', str(stats.get('last_optimization', 'Never'))
            )

            console.print(metrics_table)

            # Performance metrics
            perf_metrics = stats.get('performance_metrics', {})
            if perf_metrics:
                console.print('\n[bold]üìä Performance Metrics:[/bold]')
                for key, value in perf_metrics.items():
                    if isinstance(value, float):
                        console.print(f'  {key}: {value:.2f}')
                    else:
                        console.print(f'  {key}: {value}')

        except Exception as e:
            console.print(f'[red]‚ùå L·ªói khi hi·ªÉn th·ªã metrics: {e}[/red]')


@click.command()
@click.argument('files', nargs=-1, type=click.Path(exists=True))
@click.option(
    '--mode',
    '-m',
    type=click.Choice(['interview', 'chat', 'both']),
    default='both',
    help='Ch·ªçn ch·∫ø ƒë·ªô: interview (ph·ªèng v·∫•n), chat (tr√≤ chuy·ªán), both (c·∫£ hai)',
)
@click.option('--shuffle', '-s', is_flag=True, help='X√°o tr·ªôn th·ª© t·ª± c√¢u h·ªèi')
@click.option('--limit', '-l', type=int, help='Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng c√¢u h·ªèi')
@click.option('--verbose', '-v', is_flag=True, help='Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt')
@click.option(
    '--workspace',
    '-w',
    type=click.Path(exists=True),
    help='ƒê∆∞·ªùng d·∫´n workspace ƒë·ªÉ load to√†n b·ªô',
)
@click.option(
    '--folders',
    '-f',
    type=str,
    help='Danh s√°ch folders c√°ch nhau b·ªüi d·∫•u ph·∫©y (vd: getting-started,pipelines)',
)
@click.option('--include-python', is_flag=True, help='Bao g·ªìm ph√¢n t√≠ch file Python')
@click.option(
    '--max-file-size',
    type=int,
    default=1024 * 1024,
    help='K√≠ch th∆∞·ªõc file t·ªëi ƒëa (bytes)',
)
@click.option(
    '--exclude-folders',
    type=str,
    help='Lo·∫°i tr·ª´ folders (vd: __pycache__,node_modules)',
)
def main(
    files,
    mode,
    shuffle,
    limit,
    verbose,
    workspace,
    folders,
    include_python,
    max_file_size,
    exclude_folders,
):
    """
    AI Interview Agent - Hugging Face Knowledge Assessment

    Ph√¢n t√≠ch c√°c file .md v√† t·∫°o phi√™n ph·ªèng v·∫•n t∆∞∆°ng t√°c.

    Examples:
        # Traditional file-based loading
        python main.py getting-started/questions.md getting-started/introduction.md
        python main.py *.md --mode chat

        # New workspace loading
        python main.py --workspace . --mode chat
        python main.py --workspace . --folders 'getting-started,pipelines'
        python main.py --workspace . --include-python --exclude-folders '__pycache__'
    """

    # Banner
    console.print(
        Panel.fit(
            '[bold blue]ü§ñ AI Interview Agent[/bold blue]\n'
            '[dim]Hugging Face Knowledge Assessment[/dim]\n'
            f'[green]Mode: {mode.upper()}[/green]',
            title='Welcome',
            border_style='blue',
        )
    )

    # Kh·ªüi t·∫°o agent
    agent = InterviewAgent()

    # Configure workspace loading if enabled
    if workspace or folders or include_python:
        # Configure workspace loader
        config = WorkspaceConfig()
        config.enable_code_analysis = include_python
        config.max_file_size = max_file_size

        if exclude_folders:
            config.exclude_folders = exclude_folders.split(',')

        agent.workspace_loader.config = config

        # Determine workspace path
        workspace_path = workspace or '.'

        # Parse folders if specified
        selected_folders = folders.split(',') if folders else None

        # Load workspace content
        console.print(f'\n[bold]üåê Loading workspace: {workspace_path}[/bold]')
        if selected_folders:
            console.print(
                f'[yellow]üìÅ Selected folders: {", ".join(selected_folders)}[/yellow]'
            )

        knowledge_base = agent.workspace_loader.load_workspace_content(
            workspace_path, selected_folders or []
        )

        # Set knowledge base and load questions
        agent.knowledge_base = knowledge_base
        agent.questions = []

        # Try to load questions from workspace structure
        workspace_structure = agent.workspace_loader.discover_workspace(workspace_path)
        parser = MarkdownParser()

        for question_file in workspace_structure['question_files']:
            questions = parser.parse_questions(question_file)
            agent.questions.extend(questions)

        console.print(
            f'[green]‚úì Loaded {len(knowledge_base)} documents and {len(agent.questions)} questions[/green]'
        )

    elif files:
        # Traditional file-based loading
        console.print(f'\n[bold]üìÅ Loading {len(files)} file(s)...[/bold]')
        agent.load_data(list(files))

        if verbose:
            console.print(
                f'\n[dim]Loaded {len(agent.questions)} questions and {len(agent.knowledge_base)} documents[/dim]'
            )

    else:
        # Auto-discovery mode
        console.print('\n[yellow]üîç Auto-discovery mode[/yellow]')
        console.print('[dim]Looking for markdown files in current directory...[/dim]')

        workspace_structure = agent.workspace_loader.discover_workspace('.')
        markdown_files = workspace_structure['markdown_files']

        if markdown_files:
            console.print(f'[green]Found {len(markdown_files)} markdown files[/green]')

            # Load the discovered files
            agent.load_data(markdown_files[:10])  # Limit to first 10 files
            console.print(f'[green]‚úì Loaded {len(agent.questions)} questions[/green]')
        else:
            console.print('[red]‚ùå No markdown files found![/red]')
            console.print('\n[yellow]Examples:[/yellow]')
            console.print('  python main.py getting-started/questions.md')
            console.print('  python main.py --workspace . --mode chat')
            return

    # Apply limit
    if limit and limit < len(agent.questions):
        agent.questions = agent.questions[:limit]
        console.print(f'[yellow]Question limit applied: {limit}[/yellow]')

    # Apply shuffle
    if shuffle and agent.questions:
        import random

        random.shuffle(agent.questions)
        console.print('[yellow]Questions shuffled[/yellow]')

    # Ch·∫ø ƒë·ªô ho·∫°t ƒë·ªông
    if mode == 'interview':
        agent.start_interview()
    elif mode == 'chat':
        chat = ChatMode(agent)
        chat.start_chat()
    else:  # both
        console.print('\n[bold yellow]Ch·ªçn ch·∫ø ƒë·ªô ho·∫°t ƒë·ªông:[/bold yellow]')
        console.print('1. üéØ Ph·ªèng v·∫•n (Interview)')
        console.print('2. üí¨ Tr√≤ chuy·ªán (Chat)')
        console.print('3. üîÑ C·∫£ hai (Both)')

        choice = Prompt.ask('Ch·ªçn ch·∫ø ƒë·ªô', choices=['1', '2', '3'], default='1')

        if choice == '1':
            agent.start_interview()
        elif choice == '2':
            chat = ChatMode(agent)
            chat.start_chat()
        else:
            chat = ChatMode(agent)
            console.print(
                "\n[bold]B·∫Øt ƒë·∫ßu v·ªõi ch·∫ø ƒë·ªô chat, g√µ 'interview' ƒë·ªÉ chuy·ªÉn sang ph·ªèng v·∫•n[/bold]"
            )
            chat.start_chat()


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        console.print('\n[green]T·∫°m bi·ªát! üëã[/green]')
    except Exception as e:
        console.print(f'\n[red]L·ªói: {e}[/red]')
        if '--verbose' in sys.argv:
            import traceback

            console.print(traceback.format_exc())
