# LÃ m viá»‡c vá»›i Models tá»« Hugging Face Hub

## ğŸ“š Tá»•ng quan

Hugging Face Hub lÃ  ná»n táº£ng lÆ°u trá»¯ hÃ ng nghÃ¬n mÃ´ hÃ¬nh AI pre-trained (Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n sáºµn) cho cÃ¡c tÃ¡c vá»¥ xá»­ lÃ½ vÄƒn báº£n, hÃ¬nh áº£nh vÃ  Ã¢m thanh. ThÆ° viá»‡n **Transformers** giÃºp Ä‘Æ¡n giáº£n hÃ³a viá»‡c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh nÃ y.

## ğŸ” KhÃ¡m phÃ¡ Hugging Face Hub

### Truy cáº­p Hub
- **Website chÃ­nh**: [huggingface.co](https://huggingface.co/)
- **Danh sÃ¡ch models**: [huggingface.co/models](https://huggingface.co/models)

### TÃ­nh nÄƒng tÃ¬m kiáº¿m
- **Lá»c theo task**: Text classification, object detection, summarization...
- **Lá»c theo ngÃ´n ngá»¯**: Tiáº¿ng Viá»‡t, Tiáº¿ng Anh, v.v.
- **Lá»c theo thÆ° viá»‡n**: PyTorch, TensorFlow, JAX...
- **Tráº¡ng thÃ¡i**: Open-source (miá»…n phÃ­) hoáº·c cÃ³ phÃ­

### Model Cards
Má»—i model cÃ³ thÃ´ng tin chi tiáº¿t:
- âœ… MÃ´ táº£ vÃ  cÃ¡ch sá»­ dá»¥ng
- âœ… TÃ¡c giáº£ phÃ¡t triá»ƒn
- âœ… Giáº¥y phÃ©p (license)
- âœ… NgÃ´n ngá»¯ há»— trá»£
- âœ… KÃ­ch thÆ°á»›c file

## ğŸš€ Sá»­ dá»¥ng Pipelines

### Pipeline cÆ¡ báº£n
```python
from transformers import pipeline

# Táº¡o pipeline cho phÃ¢n loáº¡i vÄƒn báº£n
classifier = pipeline("text-classification", 
                     model="distilbert-base-uncased-finetuned-sst-2-english")

# Sá»­ dá»¥ng
result = classifier("DataCamp is awesome!")
# Káº¿t quáº£: [{'label': 'POSITIVE', 'score': 0.99}]
```

### Pipeline nÃ¢ng cao
```python
# Text generation vá»›i tham sá»‘ tÃ¹y chá»‰nh
generator = pipeline("text-generation", model="gpt2")

result = generator("Artificial intelligence is", 
                  max_length=10,           # Giá»›i háº¡n Ä‘á»™ dÃ i
                  num_return_sequences=2)  # Táº¡o 2 káº¿t quáº£ khÃ¡c nhau
```

## ğŸ“ LÆ°u trá»¯ Models

### Khi nÃ o cáº§n lÆ°u model?
- ğŸ”’ **Sá»­ dá»¥ng offline**: KhÃ´ng cÃ³ internet
- ğŸ› ï¸ **Fine-tuning**: TÃ¹y chá»‰nh model cho dá»± Ã¡n cá»¥ thá»ƒ
- ğŸ¢ **Production**: Triá»ƒn khai quy mÃ´ lá»›n
- ğŸ’¾ **Kiá»ƒm soÃ¡t storage**: Quáº£n lÃ½ dung lÆ°á»£ng

### CÃ¡ch lÆ°u model
```python
from transformers import pipeline

# Táº¡o pipeline
classifier = pipeline("text-classification", 
                     model="distilbert-base-uncased-finetuned-sst-2-english")

# LÆ°u model vÃ  tokenizer
classifier.save_pretrained("./my_model")

# Load láº¡i tá»« file local
classifier_local = pipeline("text-classification", model="./my_model")
```

## âš ï¸ LÆ°u Ã½ quan trá»ng

### KÃ­ch thÆ°á»›c Model
- **DistilBERT**: ~1GB
- **BERT Large**: ~3GB  
- **GPT-3 style models**: 10GB+
- â¡ï¸ Kiá»ƒm tra tab "Files and Versions" trÆ°á»›c khi táº£i

### Tokens
- **Token**: ÄÆ¡n vá»‹ nhá» nháº¥t mÃ  model xá»­ lÃ½ (tá»«, kÃ½ tá»± hoáº·c subword)
- **max_length**: Giá»›i háº¡n sá»‘ token Ä‘áº§u ra
- **VÃ­ dá»¥**: "Hello world" cÃ³ thá»ƒ Ä‘Æ°á»£c chia thÃ nh 2-3 tokens

### Performance Tips
- ğŸš€ Models Ä‘Æ°á»£c cache tá»± Ä‘á»™ng khi sá»­ dá»¥ng pipeline
- ğŸ’¡ Chá»‰ save local khi thá»±c sá»± cáº§n thiáº¿t
- ğŸ”„ Káº¿t quáº£ text generation sáº½ khÃ¡c nhau má»—i láº§n cháº¡y

## ğŸ“‹ Checklist cho Developer

- [ ] TÃ¬m hiá»ƒu model phÃ¹ há»£p trÃªn Hub
- [ ] Äá»c model card Ä‘á»ƒ hiá»ƒu cÃ¡ch sá»­ dá»¥ng
- [ ] Kiá»ƒm tra license vÃ  requirements
- [ ] Test vá»›i pipeline trÆ°á»›c khi integrate
- [ ] CÃ¢n nháº¯c viá»‡c save local dá»±a trÃªn use case
- [ ] Monitor performance vÃ  kÃ­ch thÆ°á»›c model

## ğŸ”— TÃ i liá»‡u tham kháº£o

- [Hugging Face Transformers Documentation](https://github.com/huggingface/transformers)
- [Model Hub](https://huggingface.co/models)
- [Pipeline Documentation](https://huggingface.co/docs/transformers/main_classes/pipelines)
