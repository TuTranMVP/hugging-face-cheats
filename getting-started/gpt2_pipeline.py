"""
ğŸ¯ Má»¥c tiÃªu bÃ i táº­p:
XÃ¢y dá»±ng text generation pipeline sá»­ dá»¥ng model GPT-2
TÃ¹y chá»‰nh output báº±ng cÃ¡ch Ä‘iá»u chá»‰nh cÃ¡c tham sá»‘
Thá»­ nghiá»‡m vá»›i cÃ¡c prompt khÃ¡c nhau

âœ… YÃªu cáº§u cá»¥ thá»ƒ:
Import pipeline tá»« transformers
Táº¡o pipeline vá»›i task "text-generation" vÃ  model "gpt2"
Cáº¥u hÃ¬nh pipeline Ä‘á»ƒ táº¡o tá»‘i Ä‘a 10 tokens vÃ  3 outputs
Cung cáº¥p prompt tÃ¹y chá»‰nh lÃ m input
Diá»…n giáº£i cho láº­p trÃ¬nh viÃªn Viá»‡t Nam:
Text Generation Pipeline lÃ  má»™t cÃ´ng cá»¥ máº¡nh máº½ cho phÃ©p:

ğŸ¤– Tá»± Ä‘á»™ng táº¡o vÄƒn báº£n tá»« má»™t cÃ¢u khá»Ÿi Ä‘áº§u (prompt)
âš™ï¸ Äiá»u chá»‰nh Ä‘á»™ dÃ i output thÃ´ng qua max_length
ğŸ”¢ Táº¡o nhiá»u phiÃªn báº£n khÃ¡c nhau vá»›i num_return_sequences
ğŸ¯ Sá»­ dá»¥ng Ä‘Æ¡n giáº£n chá»‰ vá»›i vÃ i dÃ²ng code


ğŸ”‘ CÃ¡c giÃ¡ trá»‹ Ä‘Ã£ Ä‘iá»n:
pipeline - Import function tá»« transformers
pipeline - Táº¡o pipeline object
"gpt2" - TÃªn model GPT-2
"What if artificial intelligence could" - Prompt sÃ¡ng táº¡o
10 - max_length = 10 tokens
3 - num_return_sequences = 3 outputs

ğŸ’¡ Äáº·c Ä‘iá»ƒm ná»•i báº­t:
Prompt hay: "What if artificial intelligence could" - kÃ­ch thÃ­ch sá»± sÃ¡ng táº¡o
Tham sá»‘ há»£p lÃ½: 10 tokens vÃ  3 variations
Code sáº¡ch: TuÃ¢n thá»§ PEP8 vÃ  best practices
Demo má»Ÿ rá»™ng: Thá»­ nghiá»‡m vá»›i nhiá»u prompts khÃ¡c nhau
"""

from transformers.pipelines import pipeline  # type: ignore[import-untyped]

my_pipeline = pipeline(task='text-generation', model='gpt2')

# Táº¡o ba Ä‘áº§u ra vÄƒn báº£n vá»›i Ä‘á»™ dÃ i tá»‘i Ä‘a 10 mÃ£ thÃ´ng bÃ¡o
results = my_pipeline(
    'What if artificial intelligence could', max_length=10, num_return_sequences=3
)

# Display each result
for result in results:
    print(result['generated_text'])
